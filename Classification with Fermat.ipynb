{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import  distance_matrix\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from fermat import Fermat\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de $D_Q (x,y)$ ## \n",
    "\n",
    "data = puntos sobre los cuales calculamos distnacia de fermat empírica y a esta ultima le aplicamos un kernel gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DQ(data,N,k_h =1,alpha =10, k=10, d=64,method='D'):\n",
    "    \n",
    "    distances = distance_matrix(data,data)\n",
    "    \n",
    "    f_exact = Fermat(alpha=alpha,path_method=method,k=k)\n",
    "    \n",
    "    f_exact.fit(np.matrix(distances))\n",
    "    \n",
    "    fermat_distances =  f_exact.get_distances()\n",
    "    \n",
    "\n",
    "    h =k_h *  N ** (-1/(d+4)) \n",
    "    beta = (1-alpha)/d\n",
    "\n",
    "    fermat_distances =  np.array( (1/h) *(N ** (-beta)) *fermat_distances,dtype =np.float32)\n",
    "    \n",
    "    #delta = 1 # Esto despues cambiarlo\n",
    "\n",
    "    #kernel_fermat_distances = (N **2 )* np.exp(- fermat_distances ** 2 / (2. * delta ** 2))\n",
    "    kernel_fermat_distances = (1/N) * (h ** (-d)) *  np.exp(-1* fermat_distances ** 2 / 2. ) # Le saque el delta\n",
    "    #kernel_fermat_distances =  np.exp(-1* fermat_distances ** 2 / 2. )\n",
    "    \n",
    "    return kernel_fermat_distances,fermat_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generamos data de 2 lunas \n",
    "\n",
    "$N =$ cantidad de puntos en cada luna. La muestra es de tamaño $2N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "n_samples = 2*N\n",
    "noisy_moons = datasets.make_moons(n_samples= n_samples, noise=0.14)\n",
    "\n",
    "xnoise = [noisy_moons[0][i][0] for i in range(2*N)]\n",
    "ynoise = [noisy_moons[0][i][1] for i in range(2*N)]\n",
    "plt.plot(xnoise,ynoise,'.')\n",
    "\n",
    "\n",
    "true_labels = noisy_moons[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_moon = np.array([ noisy_moons[0][i] for i in range(n_samples) if noisy_moons[1][i]==0  ])\n",
    "\n",
    "first_moon_x = [ noisy_moons[0][i][0] for i in range(n_samples) if noisy_moons[1][i]==0  ]\n",
    "first_moon_y = [ noisy_moons[0][i][1] for i in range(n_samples) if noisy_moons[1][i]==0  ]\n",
    "\n",
    "second_moon = np.array([ noisy_moons[0][i] for i in range(n_samples) if noisy_moons[1][i]==1 ])\n",
    "\n",
    "second_moon_x = [ noisy_moons[0][i][0] for i in range(n_samples) if noisy_moons[1][i]==1  ]\n",
    "second_moon_y = [ noisy_moons[0][i][1] for i in range(n_samples) if noisy_moons[1][i]==1  ]\n",
    "\n",
    "#plt.plot(first_moon_x,first_moon_y,'r.')\n",
    "#plt.plot(second_moon_x,second_moon_y,'b.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generamos data para evaluar\n",
    "\n",
    "Tomamos *test_size* puntos de cada luna y calculamos \n",
    "Para cada $p \\in  $ *noisy_moons_test* calculamos \n",
    "    $$ \\sum_{q \\in \\text{first_moon}}\\frac{1}{nh^d} K(\\frac{1}{hn^\\beta}D_Q(p,q)) \\qquad vs \\qquad  \\sum_{q \\in \\text{second_moon}} \\frac{1}{nh^d} K(\\frac{1}{hn^\\beta}D_Q(p,q))  $$\n",
    "    \n",
    "Obs: Los factores de normalizacion no los estoy teniendo en cuenta. Sería una especie de Naive Bayes con un nucleo y el estimador de Fermat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size =5000\n",
    "noisy_moons_test = datasets.make_moons(n_samples=test_size, noise=0.14)\n",
    "first_moon_test  = np.array([ noisy_moons_test[0][i] for i in range(test_size) if noisy_moons_test[1][i]==0 ])\n",
    "second_moon_test = np.array([ noisy_moons_test[0][i] for i in range(test_size) if noisy_moons_test[1][i]==1  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_size):\n",
    "    if noisy_moons_test[1][i]==0:\n",
    "        plt.plot(noisy_moons_test[0][i][0],noisy_moons_test[0][i][1],'r.')\n",
    "    else:\n",
    "         plt.plot(noisy_moons_test[0][i][0],noisy_moons_test[0][i][1],'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distances_0 = get_DQ(data = np.concatenate((first_moon,first_moon_test,second_moon_test)))\n",
    "#distances_1 = get_DQ(data = np.concatenate((second_moon,first_moon_test,second_moon_test)))fer\n",
    "distances_0,fermat_distances_0 = get_DQ(data = np.concatenate((first_moon,noisy_moons_test[0])),k_h= 1, N =N, alpha=2,d=1)\n",
    "distances_1,fermat_distances_1= get_DQ(data = np.concatenate((second_moon,noisy_moons_test[0])),k_h =1, N=N, alpha =2,d=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos si la suma correspondiente al cluster 0 es menor que la del cluster 1 para ver que etiqueta\n",
    "# le asignamos \n",
    "\n",
    "labels = (len(distances_0)-N)*[0]\n",
    "for i in range(N,len(distances_0)):\n",
    "    if np.sum(distances_0[i,:N])< np.sum(distances_1[i,:N]):\n",
    "        labels[i-N]=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters que genera "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters_2D(data,labels):\n",
    "    colours =[\".r\",\".g\",\".b\"]\n",
    "    for i in range(len(labels)):\n",
    "         plt.plot(data[i][0],data[i][1],colours[int(labels[i])])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters_2D(noisy_moons_test[0],labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(model,labels_predict,real_labels):\n",
    "    acc  =  0\n",
    "    for i in range(len(labels_predict)):\n",
    "        if labels_predict[i]==real_labels[i]:\n",
    "            acc = acc +1 \n",
    "    print(\"The accuracy of \",model, \" classifier is \", 100 * acc/len(labels_predict), \"%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_accuracy(\"Fermat\",labels,noisy_moons_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dos lunas con Naive Bayes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = GaussianNB()\n",
    "moons = np.concatenate((first_moon,second_moon))\n",
    "labels = np.zeros(len(moons))\n",
    "labels[len(first_moon):]=np.ones(len(second_moon))\n",
    "clf.fit(moons,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_predict = clf.predict(noisy_moons_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Naive Bayes\",labels_predict,noisy_moons_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters_2D(noisy_moons_test[0],labels_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate\n",
    "rf = RandomForestClassifier()  \n",
    "# Fit\n",
    "rf_model = rf.fit(moons,labels)  \n",
    "# training accuracy\n",
    "rf_model.score(moons, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = rf_model.predict(noisy_moons_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Random Forest\",labels_predict,noisy_moons_test[1])\n",
    "plot_clusters_2D(noisy_moons_test[0],labels_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits 0-1 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits(n_class=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_0  = []\n",
    "images_1 =  []\n",
    "n_training  = 10\n",
    "n_test = n_samples-n_training\n",
    "\n",
    "images_and_labels_training = images_and_labels[:n_training]\n",
    "images_and_labels_test = images_and_labels[n_training:]\n",
    "\n",
    "for index, (image, label) in enumerate(images_and_labels_training):\n",
    "    if label == 0 :\n",
    "        images_0.append(data[index])\n",
    "    else:\n",
    "        images_1.append(data[index]) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_0 = np.array(images_0)\n",
    "images_1 = np.array(images_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits with Fermat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel_digits_distances_0, fermat_digits_distances_0  = get_DQ(data=np.concatenate((images_0,data[n_training:])),k_h=1,N=n_training,alpha=2,k=20,d=64,method='FW')\n",
    "kernel_digits_distances_1, fermat_digits_distances_1  = get_DQ(data=np.concatenate((images_1,data[n_training:])),k_h=1,N=n_training,alpha=2,k=20,d=64,method='FW')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_digits_distances_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = (n_test)*[0]\n",
    "offset_0 = len(images_0)\n",
    "offset_1 = len(images_1) \n",
    "for i in range(n_test):\n",
    "    if np.sum(kernel_digits_distances_0[offset_0+i,:offset_0])< np.sum(kernel_digits_distances_1[offset_1+i,:offset_1]):\n",
    "        labels_predict[i]=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_accuracy(\"Fermat\",labels_predict,digits.target[n_training:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "rf = RandomForestClassifier()  \n",
    "# Fit\n",
    "rf_model = rf.fit(data[:n_training],digits.target[:n_training])  \n",
    "# training accuracy\n",
    "rf_model.score(data[:n_training],digits.target[:n_training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = rf.predict(data[n_training:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Random Forest\",labels_predict,digits.target[n_training:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(data[:n_training],digits.target[:n_training])\n",
    "\n",
    "clf.score(data[:n_training],digits.target[:n_training])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = clf.predict(data[n_training:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Naive Bayes\",labels_predict,digits.target[n_training:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two circles\n",
    "\n",
    "Generamos una muestra de tamaño *n_samples*  y genera dos círculos uniformes de tamaño *n_samples/2* con ruido *noise*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training =100\n",
    "\n",
    "noisy_circles = datasets.make_circles(n_samples=n_training, factor=.2,\n",
    "                                      noise=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_training):\n",
    "     plt.plot(noisy_circles[0][i][0],noisy_circles[0][i][1],'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_circle = np.array([ noisy_circles[0][i] for i in range(n_training) if noisy_circles[1][i]==0  ])\n",
    "\n",
    "second_circle = np.array([ noisy_circles[0][i] for i in range(n_training) if noisy_circles[1][i]==1 ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_circle_x = [ noisy_circles[0][i][0] for i in range(n_training) if noisy_circles[1][i]==0  ]\n",
    "first_circle_y = [ noisy_circles[0][i][1] for i in range(n_training) if noisy_circles[1][i]==0  ]\n",
    "\n",
    "second_circle_x = [ noisy_circles[0][i][0] for i in range(n_training) if noisy_circles[1][i]==1  ]\n",
    "second_circle_y = [ noisy_circles[0][i][1] for i in range(n_training) if noisy_circles[1][i]==1  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 1000\n",
    "noisy_circles_test = datasets.make_circles(n_samples=n_test,factor=.5, noise=.2)\n",
    "first_circle_test  = np.array([ noisy_circles_test[0][i] for i in range(n_test) if noisy_circles_test[1][i]==0 ])\n",
    "second_circle_test = np.array([ noisy_circles_test[0][i] for i in range(n_test) if noisy_circles_test[1][i]==1  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_clusters_2D(noisy_circles_test[0],noisy_circles_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two circles with Fermat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel_circles_distances_0, fermat_circles_distances_0  = get_DQ(data=np.concatenate((first_circle,noisy_circles_test[0])),k_h=10,N=n_training,alpha=2,k=10,d=1)\n",
    "kernel_circles_distances_1, fermat_circles_distances_1  = get_DQ(data=np.concatenate((second_circle,noisy_circles_test[0])),k_h=10,N=n_training,alpha=2,k=10,d=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos si la suma correspondiente al cluster 0 es menor que la del cluster 1 para ver que etiqueta\n",
    "# le asignamos \n",
    "labels_predict = n_test*[0]\n",
    "for i in range(n_training//2,n_training//2+n_test):\n",
    "    if np.sum(kernel_circles_distances_0[i,:n_training])< np.sum(kernel_circles_distances_1[i,:n_training]):\n",
    "        labels_predict[i-n_training//2]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Fermat\",labels_predict,noisy_circles_test[1])\n",
    "#plot_clusters_2D(noisy_circles_test[0],labels_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two circles with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "rf = RandomForestClassifier()  \n",
    "# Fit\n",
    "rf_model = rf.fit(noisy_circles[0],noisy_circles[1])  \n",
    "# training accuracy\n",
    "rf_model.score(noisy_circles[0],noisy_circles[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = rf.predict(noisy_circles_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Random Forest\",labels_predict,noisy_circles_test[1])\n",
    "#plot_clusters_2D(noisy_circles_test[0],labels_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two cirlces Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "gnb_model = GaussianNB()\n",
    "# Fit\n",
    "gnb_model = rf.fit(noisy_circles[0],noisy_circles[1])  \n",
    "# training accuracy\n",
    "gnb_model.score(noisy_circles[0],noisy_circles[1])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = gnb_model.predict(noisy_circles_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Naive Bayes\",labels_predict,noisy_circles_test[1])\n",
    "#plot_clusters_2D(noisy_circles_test[0],labels_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j in range(1,10):\n",
    "    kernel_circles_distances_0, fermat_circles_distances_0  = get_DQ(data=np.concatenate((first_circle,noisy_circles_test[0])),k_h=j/100,N=n_training,alpha=2,k=10)\n",
    "    kernel_circles_distances_1, fermat_circles_distances_1  = get_DQ(data=np.concatenate((second_circle,noisy_circles_test[0])),k_h=j/100,N=n_training,alpha=2,k=10)\n",
    "    labels_predict = n_test*[0]\n",
    "    for i in range(n_training//2,n_training//2+n_test):\n",
    "        if np.sum(kernel_circles_distances_0[i,:n_training])< np.sum(kernel_circles_distances_1[i,:n_training]):\n",
    "            labels_predict[i-n_training//2]=1\n",
    "    model_accuracy(\"Fermat\",labels_predict,noisy_circles_test[1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fermat",
   "language": "python",
   "name": "fermat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
