{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import  distance_matrix\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from fermat import Fermat\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de $D_Q (x,y)$ ## \n",
    "\n",
    "data = puntos sobre los cuales calculamos distnacia de fermat empírica y a esta ultima le aplicamos un kernel gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DQ(data, N, k_h=1, alpha=10, k=10, d=64, method=\"D\"):\n",
    "    distances = distance_matrix(data, data)\n",
    "    f_exact = Fermat(alpha=alpha, path_method=method, k=k)\n",
    "    f_exact.fit(distances)  # Esto NO puede ser una `np.matrix`, DEBE(?) ser un `np.ndarray`\n",
    "    fermat_distances = f_exact.get_distances()\n",
    "    h = k_h * N ** (-1 / (d + 4))\n",
    "    beta = (1 - alpha) / d\n",
    "    fermat_distances = np.array(\n",
    "        (1 / h) * (N ** (-beta)) * fermat_distances, dtype=np.float32\n",
    "    )\n",
    "    # delta = 1 # Esto despues cambiarlo\n",
    "    # kernel_fermat_distances = (N **2 )* np.exp(- fermat_distances ** 2 / (2. * delta ** 2))\n",
    "    kernel_fermat_distances = (\n",
    "        (1 / N) * (h ** (-d)) * np.exp(-1 * fermat_distances**2 / 2.0)\n",
    "    )  # Le saque el delta\n",
    "    # kernel_fermat_distances =  np.exp(-1* fermat_distances ** 2 / 2. )\n",
    "    return kernel_fermat_distances, fermat_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generamos data de 2 lunas \n",
    "\n",
    "$N =$ cantidad de puntos en cada luna. La muestra es de tamaño $2N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "n_samples = 2 * N\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=0.14)\n",
    "xnoise = [noisy_moons[0][i][0] for i in range(2 * N)]\n",
    "ynoise = [noisy_moons[0][i][1] for i in range(2 * N)]\n",
    "true_labels = noisy_moons[1]\n",
    "plt.plot(xnoise, ynoise, \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_moon = np.array(\n",
    "    [noisy_moons[0][i] for i in range(n_samples) if noisy_moons[1][i] == 0]\n",
    ")\n",
    "first_moon_x = [\n",
    "    noisy_moons[0][i][0] for i in range(n_samples) if noisy_moons[1][i] == 0\n",
    "]\n",
    "first_moon_y = [\n",
    "    noisy_moons[0][i][1] for i in range(n_samples) if noisy_moons[1][i] == 0\n",
    "]\n",
    "second_moon = np.array(\n",
    "    [noisy_moons[0][i] for i in range(n_samples) if noisy_moons[1][i] == 1]\n",
    ")\n",
    "second_moon_x = [\n",
    "    noisy_moons[0][i][0] for i in range(n_samples) if noisy_moons[1][i] == 1\n",
    "]\n",
    "second_moon_y = [\n",
    "    noisy_moons[0][i][1] for i in range(n_samples) if noisy_moons[1][i] == 1\n",
    "]\n",
    "# plt.plot(first_moon_x,first_moon_y,'r.')\n",
    "# plt.plot(second_moon_x,second_moon_y,'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generamos data para evaluar\n",
    "\n",
    "Tomamos *test_size* puntos de cada luna y calculamos \n",
    "Para cada $p \\in  $ *noisy_moons_test* calculamos \n",
    "    $$ \\sum_{q \\in \\text{first_moon}}\\frac{1}{nh^d} K(\\frac{1}{hn^\\beta}D_Q(p,q)) \\qquad vs \\qquad  \\sum_{q \\in \\text{second_moon}} \\frac{1}{nh^d} K(\\frac{1}{hn^\\beta}D_Q(p,q))  $$\n",
    "    \n",
    "Obs: Los factores de normalizacion no los estoy teniendo en cuenta. Sería una especie de Naive Bayes con un nucleo y el estimador de Fermat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 50\n",
    "noisy_moons_test = datasets.make_moons(n_samples=test_size, noise=0.14)\n",
    "first_moon_test = np.array(\n",
    "    [noisy_moons_test[0][i] for i in range(test_size) if noisy_moons_test[1][i] == 0]\n",
    ")\n",
    "second_moon_test = np.array(\n",
    "    [noisy_moons_test[0][i] for i in range(test_size) if noisy_moons_test[1][i] == 1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_size):\n",
    "    if noisy_moons_test[1][i] == 0:\n",
    "        plt.plot(noisy_moons_test[0][i][0], noisy_moons_test[0][i][1], \"r.\")\n",
    "    else:\n",
    "        plt.plot(noisy_moons_test[0][i][0], noisy_moons_test[0][i][1], \"b.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances_0 = get_DQ(data = np.concatenate((first_moon,first_moon_test,second_moon_test)))\n",
    "# distances_1 = get_DQ(data = np.concatenate((second_moon,first_moon_test,second_moon_test)))fer\n",
    "distances_0, fermat_distances_0 = get_DQ(\n",
    "    data=np.concatenate((first_moon, noisy_moons_test[0])), k_h=1, N=N, alpha=2, d=1\n",
    ")\n",
    "distances_1, fermat_distances_1 = get_DQ(\n",
    "    data=np.concatenate((second_moon, noisy_moons_test[0])), k_h=1, N=N, alpha=2, d=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos si la suma correspondiente al cluster 0 es menor que la del cluster 1 para ver que etiqueta\n",
    "# le asignamos\n",
    "labels = (len(distances_0) - N) * [0]\n",
    "for i in range(N, len(distances_0)):\n",
    "    if np.sum(distances_0[i, :N]) < np.sum(distances_1[i, :N]):\n",
    "        labels[i - N] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters que genera "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters_2D(data, labels):\n",
    "    colours = [\".r\", \".g\", \".b\"]\n",
    "    for i in range(len(labels)):\n",
    "        plt.plot(data[i][0], data[i][1], colours[int(labels[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters_2D(noisy_moons_test[0], labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(model, labels_predict, real_labels):\n",
    "    acc = 0\n",
    "    for i in range(len(labels_predict)):\n",
    "        if labels_predict[i] == real_labels[i]:\n",
    "            acc = acc + 1\n",
    "    print(\n",
    "        \"The accuracy of \",\n",
    "        model,\n",
    "        \" classifier is \",\n",
    "        100 * acc / len(labels_predict),\n",
    "        \"%\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Fermat\", labels, noisy_moons_test[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dos lunas con Naive Bayes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "moons = np.concatenate((first_moon, second_moon))\n",
    "labels = np.zeros(len(moons))\n",
    "labels[len(first_moon) :] = np.ones(len(second_moon))\n",
    "clf.fit(moons, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = clf.predict(noisy_moons_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Naive Bayes\", labels_predict, noisy_moons_test[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters_2D(noisy_moons_test[0], labels_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate\n",
    "rf = RandomForestClassifier()\n",
    "# Fit\n",
    "rf_model = rf.fit(moons, labels)\n",
    "# training accuracy\n",
    "rf_model.score(moons, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = rf_model.predict(noisy_moons_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Random Forest\", labels_predict, noisy_moons_test[1])\n",
    "plot_clusters_2D(noisy_moons_test[0], labels_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits 0-1 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits(n_class=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    plt.title(\"Training: %i\" % label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1)) / 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_0 = []\n",
    "images_1 = []\n",
    "n_training = 10\n",
    "n_test = n_samples - n_training\n",
    "\n",
    "images_and_labels_training = images_and_labels[:n_training]\n",
    "images_and_labels_test = images_and_labels[n_training:]\n",
    "\n",
    "for index, (image, label) in enumerate(images_and_labels_training):\n",
    "    if label == 0:\n",
    "        images_0.append(data[index])\n",
    "    else:\n",
    "        images_1.append(data[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_0 = np.array(images_0)\n",
    "images_1 = np.array(images_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits with Fermat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_digits_distances_0, fermat_digits_distances_0 = get_DQ(\n",
    "    data=np.concatenate((images_0, data[n_training:])),\n",
    "    k_h=1,\n",
    "    N=n_training,\n",
    "    alpha=2,\n",
    "    k=20,\n",
    "    d=64,\n",
    "    method=\"FW\",\n",
    ")\n",
    "kernel_digits_distances_1, fermat_digits_distances_1 = get_DQ(\n",
    "    data=np.concatenate((images_1, data[n_training:])),\n",
    "    k_h=1,\n",
    "    N=n_training,\n",
    "    alpha=2,\n",
    "    k=20,\n",
    "    d=64,\n",
    "    method=\"FW\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_digits_distances_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = (n_test) * [0]\n",
    "offset_0 = len(images_0)\n",
    "offset_1 = len(images_1)\n",
    "for i in range(n_test):\n",
    "    if np.sum(kernel_digits_distances_0[offset_0 + i, :offset_0]) < np.sum(\n",
    "        kernel_digits_distances_1[offset_1 + i, :offset_1]\n",
    "    ):\n",
    "        labels_predict[i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Fermat\", labels_predict, digits.target[n_training:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "rf = RandomForestClassifier()\n",
    "# Fit\n",
    "rf_model = rf.fit(data[:n_training], digits.target[:n_training])\n",
    "# training accuracy\n",
    "rf_model.score(data[:n_training], digits.target[:n_training])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = rf.predict(data[n_training:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Random Forest\", labels_predict, digits.target[n_training:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(data[:n_training], digits.target[:n_training])\n",
    "\n",
    "clf.score(data[:n_training], digits.target[:n_training])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = clf.predict(data[n_training:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Naive Bayes\", labels_predict, digits.target[n_training:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two circles\n",
    "\n",
    "Generamos una muestra de tamaño *n_samples*  y genera dos círculos uniformes de tamaño *n_samples/2* con ruido *noise*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training = 100\n",
    "\n",
    "noisy_circles = datasets.make_circles(n_samples=n_training, factor=0.2, noise=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_training):\n",
    "    plt.plot(noisy_circles[0][i][0], noisy_circles[0][i][1], \"r.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_circle = np.array(\n",
    "    [noisy_circles[0][i] for i in range(n_training) if noisy_circles[1][i] == 0]\n",
    ")\n",
    "\n",
    "second_circle = np.array(\n",
    "    [noisy_circles[0][i] for i in range(n_training) if noisy_circles[1][i] == 1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_circle_x = [\n",
    "    noisy_circles[0][i][0] for i in range(n_training) if noisy_circles[1][i] == 0\n",
    "]\n",
    "first_circle_y = [\n",
    "    noisy_circles[0][i][1] for i in range(n_training) if noisy_circles[1][i] == 0\n",
    "]\n",
    "\n",
    "second_circle_x = [\n",
    "    noisy_circles[0][i][0] for i in range(n_training) if noisy_circles[1][i] == 1\n",
    "]\n",
    "second_circle_y = [\n",
    "    noisy_circles[0][i][1] for i in range(n_training) if noisy_circles[1][i] == 1\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 1000\n",
    "noisy_circles_test = datasets.make_circles(n_samples=n_test, factor=0.5, noise=0.2)\n",
    "first_circle_test = np.array(\n",
    "    [noisy_circles_test[0][i] for i in range(n_test) if noisy_circles_test[1][i] == 0]\n",
    ")\n",
    "second_circle_test = np.array(\n",
    "    [noisy_circles_test[0][i] for i in range(n_test) if noisy_circles_test[1][i] == 1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_clusters_2D(noisy_circles_test[0],noisy_circles_test[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two circles with Fermat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_circles_distances_0, fermat_circles_distances_0 = get_DQ(\n",
    "    data=np.concatenate((first_circle, noisy_circles_test[0])),\n",
    "    k_h=10,\n",
    "    N=n_training,\n",
    "    alpha=2,\n",
    "    k=10,\n",
    "    d=1,\n",
    ")\n",
    "kernel_circles_distances_1, fermat_circles_distances_1 = get_DQ(\n",
    "    data=np.concatenate((second_circle, noisy_circles_test[0])),\n",
    "    k_h=10,\n",
    "    N=n_training,\n",
    "    alpha=2,\n",
    "    k=10,\n",
    "    d=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos si la suma correspondiente al cluster 0 es menor que la del cluster 1 para ver que etiqueta\n",
    "# le asignamos\n",
    "labels_predict = n_test * [0]\n",
    "for i in range(n_training // 2, n_training // 2 + n_test):\n",
    "    if np.sum(kernel_circles_distances_0[i, :n_training]) < np.sum(\n",
    "        kernel_circles_distances_1[i, :n_training]\n",
    "    ):\n",
    "        labels_predict[i - n_training // 2] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Fermat\", labels_predict, noisy_circles_test[1])\n",
    "# plot_clusters_2D(noisy_circles_test[0],labels_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two circles with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "rf = RandomForestClassifier()\n",
    "# Fit\n",
    "rf_model = rf.fit(noisy_circles[0], noisy_circles[1])\n",
    "# training accuracy\n",
    "rf_model.score(noisy_circles[0], noisy_circles[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = rf.predict(noisy_circles_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Random Forest\", labels_predict, noisy_circles_test[1])\n",
    "# plot_clusters_2D(noisy_circles_test[0],labels_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two cirlces Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "gnb_model = GaussianNB()\n",
    "# Fit\n",
    "gnb_model = rf.fit(noisy_circles[0], noisy_circles[1])\n",
    "# training accuracy\n",
    "gnb_model.score(noisy_circles[0], noisy_circles[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predict = gnb_model.predict(noisy_circles_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(\"Naive Bayes\", labels_predict, noisy_circles_test[1])\n",
    "# plot_clusters_2D(noisy_circles_test[0],labels_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1, 10):\n",
    "    kernel_circles_distances_0, fermat_circles_distances_0 = get_DQ(\n",
    "        data=np.concatenate((first_circle, noisy_circles_test[0])),\n",
    "        k_h=j / 100,\n",
    "        N=n_training,\n",
    "        alpha=2,\n",
    "        k=10,\n",
    "    )\n",
    "    kernel_circles_distances_1, fermat_circles_distances_1 = get_DQ(\n",
    "        data=np.concatenate((second_circle, noisy_circles_test[0])),\n",
    "        k_h=j / 100,\n",
    "        N=n_training,\n",
    "        alpha=2,\n",
    "        k=10,\n",
    "    )\n",
    "    labels_predict = n_test * [0]\n",
    "    for i in range(n_training // 2, n_training // 2 + n_test):\n",
    "        if np.sum(kernel_circles_distances_0[i, :n_training]) < np.sum(\n",
    "            kernel_circles_distances_1[i, :n_training]\n",
    "        ):\n",
    "            labels_predict[i - n_training // 2] = 1\n",
    "    model_accuracy(\"Fermat\", labels_predict, noisy_circles_test[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fermat",
   "language": "python",
   "name": "fermat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
