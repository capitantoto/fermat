{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00. Primer Acercamiento a Clasificación con Distancia de Fermat: LandmarksClassifier\n",
    "La clase `fermat.Fermat` sólo devuelve distancias entre las observaciones de entrenamiento `X_train` pasadas a `Fermat.fit(X_train)`. Para usar la estimación $D_{\\mathbb{X}_n}$ de la distancia de Fermat $\\mathcal{D_f}$ en tareas de clasificación, hay que extenderla a puntos no observados.\n",
    "\n",
    "En este _notebook_ propongo la versión más bruta posible: para cada clase de entrenamiento (`X_train[y_train == cls]`), agregar la observación a predecir a la clase, calcular las nuevas distancias $D_{\\mathbb{X}_{n+1}}$, y tomar el promedio de las distancias de la observación a los elementos de la clase de entrenamiento. Asignar la observación a la clase con menor distancia promedio.\n",
    "\n",
    "Una sofisticación inmediata: es posible calcular las distancias de una nueva observación `x` a una muestra de tamaño `n`, en orden `n` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from fermat import Fermat\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "N, D = X.shape\n",
    "N, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = y.unique()\n",
    "all_distances = distance_matrix(X, X)\n",
    "cls_distances = {cls: distance_matrix(X[y == cls], X[y == cls]) for cls in classes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances.shape, {i: X.shape for i, X in cls_distances.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUIDADO**: Si tomo `f = Fermat(alpha=4, path_method=\"FW\", ...)`\n",
    "Sucesivas llamadas a `f.fit(X)` retornan una nueva instancia Fermat fiteada, pero fitean también el `f` \"de base\". Es un comportamiento esperado para los BaseEstimator de sklearn. Es problemático, el `partial` te deja trabajar con un \"factory\" manejable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "f = partial(Fermat, alpha=4, path_method=\"FW\")\n",
    "f_all = f().fit(all_distances)\n",
    "f_cls = {cls: f().fit(cls_distances[cls]) for cls in classes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any two points decide if they belong to the same class or not according to the distance in every class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_through(p, q, cls):\n",
    "    nodes = pd.concat([X.loc[[p, q]], X[y == cls]])\n",
    "    dist_mat = distance_matrix(X, X)\n",
    "    return f().fit(dist_mat).get_distance(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, q in np.random.randint(0, N, (3, 2)):\n",
    "    print(f\"p := {X.loc[p].values} (class {y[p]})\")\n",
    "    print(f\"q := {X.loc[q].values} (class {y[q]})\")\n",
    "    dists = {}\n",
    "    dists[\"all\"] = f_all.get_distance(p, q)\n",
    "    for cls in classes:\n",
    "        dists[cls] = get_distance_through(p, q, cls)\n",
    "    print(pd.Series(dists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No tiene mucha utilidad el paquete de Fermat para clasificar as-is o estoy loco? No generaliza bien la distancia a nuevos puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-out-training predictions for FermatKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.datasets import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import RandomState\n",
    "from fermat.kmedoids import KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarksClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(\n",
    "        self, alpha=2, k=5, method=\"kmedoids\", seed=None\n",
    "    ):  # number of landmarks to take from each class\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "        self.seed = seed or np.random.randint(2**32 - 1)\n",
    "        self.rs = RandomState(self.seed)\n",
    "        if method not in [\"kmedoids\", \"random\"]:\n",
    "            raise ValueError(f\"{self.method} is not a valid landmarks' choosing method\")\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.landmarks_ = {}\n",
    "        for cls in np.unique(y):\n",
    "            X_cls = X[y == cls]\n",
    "            n_cls = X_cls.shape[0]\n",
    "            if self.method == \"kmedoids\":\n",
    "                fmt = Fermat(alpha=self.alpha, path_method=\"FW\", seed=self.seed)\n",
    "                fmt.fit(euclidean_distances(X_cls))\n",
    "                km = KMedoids(iterations=10, seed=self.seed)\n",
    "                distance_matrix = fmt.get_distances()\n",
    "                labels = km(distance_matrix, min(self.k, n_cls))\n",
    "                self.landmarks_[cls] = X_cls[km._find_centers(distance_matrix, labels)]\n",
    "            else:\n",
    "                self.landmarks_[cls] = X_cls[self.rs.randint(0, n_cls)]\n",
    "\n",
    "    def _distances(self, x):\n",
    "        distances = {}\n",
    "        for cls, landmarks in self.landmarks_.items():\n",
    "            X_cls = np.vstack([x, landmarks])\n",
    "            fmt = Fermat(alpha=self.alpha, path_method=\"FW\", seed=self.seed)\n",
    "            fmt.fit(euclidean_distances(X_cls))\n",
    "            distance_matrix = fmt.get_distances()\n",
    "            distances[cls] = distance_matrix[0].mean()  # x is at th the top of X_cls\n",
    "        return distances\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = self._distances(x)\n",
    "        return min(distances, key=distances.get)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.apply_along_axis(lclf._predict, 1, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    n_iter=16,\n",
    "    test_sizes=[0.1, 0.5],\n",
    "    datasets=[\"digits\", \"iris\", \"breast_cancer\", \"wine\", \"diabetes\"],\n",
    "    alphas=[0.5, 1, 1.5, 2, 3, 4],\n",
    "    ks=[3, 10, 30, 100],\n",
    "    methods=[\"kmedoids\", \"random\"],\n",
    "    # n_estimators=[3, 10, 30]   # TODO: LATER\n",
    "    # max_depths=[3, 6, 9]\n",
    ")\n",
    "simple_config = dict(\n",
    "    n_iter=1,\n",
    "    test_sizes=[0.1],\n",
    "    datasets=[\"digits\"],\n",
    "    alphas=[2],\n",
    "    ks=[10],\n",
    "    methods=[\"kmedoids\"],\n",
    "    # n_estimators=[3, 10, 30]   # TODO: LATER\n",
    "    # max_depths=[3, 6, 9]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(n_iter, test_sizes, datasets, alphas, ks, methods):\n",
    "    from sklearn import datasets as sk_datasets\n",
    "    runs = []\n",
    "    for ds, size in it.product(datasets, test_sizes):\n",
    "        log = {\"ds\": ds, \"size\": size}\n",
    "        print(log)\n",
    "        loader = eval(f\"sk_datasets.load_{ds}\")\n",
    "        X, y = loader(return_X_y=True)\n",
    "        for i in range(n_iter):\n",
    "            log[\"i\"] = i\n",
    "            print(log)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=size, random_state=i\n",
    "            )\n",
    "            try:\n",
    "                rfclf = RandomForestClassifier(n_estimators=10)\n",
    "                rfclf.fit(X_train, y_train)\n",
    "                runs.append({\"method\": \"rf\", \"score\": rfclf.score(X_test, y_test), **log})\n",
    "            except:\n",
    "                print(f\"Problem with RF for {log}\")\n",
    "            for alpha, k, method in it.product(alphas, ks, methods):\n",
    "                # New keys must be at the end to replace previous values in the loop\n",
    "                log = {**log, \"alpha\": alpha, \"k\": k, \"method\": method}\n",
    "                print(log)\n",
    "                try:\n",
    "                    lclf = LandmarksClassifier(alpha=alpha, k=k, method=method)\n",
    "                    lclf.fit(X_train, y_train)\n",
    "                    runs.append({\"score\": lclf.score(X_test, y_test), **log})\n",
    "                except Exception as e:\n",
    "                    print(f\"Problem with Landmarks for {log}\")\n",
    "\n",
    "    return runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = run(**simple_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "rfclf = RandomForestClassifier(n_estimators=10)\n",
    "rfclf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfclf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {}\n",
    "alpha = 2\n",
    "seed = 34\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=seed\n",
    ")\n",
    "for cls in np.unique(y_train):\n",
    "    X = X_train[y_train == cls]\n",
    "    n = X.shape[0]\n",
    "    fmt = Fermat(alpha=alpha, path_method=\"FW\", seed=seed)\n",
    "    fmt.fit(euclidean_distances(X))\n",
    "    classes[cls] = dict(verts=X, dists=fmt.get_distances())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[0][\"dists\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.random.randint(0, X_test.shape[0])\n",
    "x, y = X_test[ix], y_test[ix]\n",
    "# plt.imshow(1- x.reshape(8,8), cmap=\"gray\")\n",
    "# plt.suptitle(y), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix, y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = 2\n",
    "klass = classes[cls]\n",
    "verts, dists = klass[\"verts\"], klass[\"dists\"]\n",
    "n = verts.shape[0]\n",
    "to_verts = euclidean_distances(x.reshape(1, -1), verts)[0] ** alpha\n",
    "all_dists = fmt.fit(euclidean_distances(np.vstack([x, verts]))).get_distances()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dists = [min(to_verts + dists[:, i]) for i in range(n)]\n",
    "assert np.allclose([0] + new_dists, all_dists[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉXITO PAPÁÁÁÁÁÁÁ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "kern = norm.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = np.mean(all_dists), np.std(all_dists)\n",
    "hs = np.linspace(mu - 2 * sigma, mu + 2 * sigma, 5)  # bandwiths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "fhats = []\n",
    "for x in X_test:\n",
    "    fhat = {}\n",
    "    for cls in classes.keys():\n",
    "        klass = classes[cls]\n",
    "        verts, dists = klass[\"verts\"], klass[\"dists\"]\n",
    "        n = verts.shape[0]\n",
    "        to_verts = euclidean_distances(x.reshape(1, -1), verts)[0] ** alpha\n",
    "        fmt_dists = [min(to_verts + dists[:, i]) for i in range(n)]\n",
    "        # print(cls, np.mean(fmt_dists))\n",
    "        fhat[cls] = (1 / h**D) * np.mean([kern(d / h) for d in fmt_dists])\n",
    "    fhats.append(fhat)\n",
    "    preds.append(pd.Series(fhat).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densities = pd.DataFrame(fhats)\n",
    "densities[\"true\"] = y_test\n",
    "densities[\"pred\"] = preds\n",
    "densities#[densities.true != densities.pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densities = pd.DataFrame(fhats)\n",
    "densities[\"true\"] = y_test\n",
    "densities[\"pred\"] = preds\n",
    "densities[densities.true != densities.pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = pd.DataFrame({\"y_test\": y_test, \"preds\": preds}).groupby([\"y_test\", \"preds\"]).apply(\n",
    "    len\n",
    ").rename(\"n\").reset_index().pivot(\"y_test\", \"preds\").fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(confusion, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(preds).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test == preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10], preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).value_counts(), pd.Series(preds).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i: np.mean(cls[\"dists\"]) for i, cls in classes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(runs).to_csv(\"runs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"runs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.alpha.isna() | (df.k == 100)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fermat",
   "language": "python",
   "name": "fermat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
