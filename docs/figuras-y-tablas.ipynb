{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figuras y Tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train with d2_log_loss instead of neg_log_loss score (!)\n",
    "# TODO: De-ignore from gitinfo docs/img and docs/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import pickle\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import close\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "from fkdc import config\n",
    "from fkdc.config import _get_run_seeds, clasificadores, grillas, main_seed\n",
    "from fkdc.datasets import Dataset\n",
    "from fkdc.datasets import synth_datasets, found_datasets, datasets\n",
    "\n",
    "from fkdc.tarea import Tarea\n",
    "from fkdc.viz import (\n",
    "    decision_boundary,\n",
    "    default_palette,\n",
    "    load_infos,\n",
    "    loss_contour,\n",
    "    parse_basic_info,\n",
    ")\n",
    "\n",
    "# Los experimentos del 29.10.2024 corrieron con main_seed = 2024\n",
    "# Los experimentos del 19.05.2025 corrieron con main_seed = 2206\n",
    "# Los experimentos del 23.05.2025 corrieron con main_seed = 2411\n",
    "# Los experimentos del 07.06.2025 corrieron con main_seed = 1312\n",
    "# Los experimentos del 12.06.2025 corrieron con main_seed = 1312 (igual a 07.06.2025)\n",
    "run_seeds = _get_run_seeds()\n",
    "plotting_seed = run_seeds[0]\n",
    "\n",
    "root_dir = Path(\"/Users/gonzalo/Git/fkdc\")\n",
    "run_dir = root_dir / \"sandbox/v5/infos\"\n",
    "datasets_dir = run_dir / \"../datasets\"\n",
    "img_dir = root_dir / \"docs/img\"\n",
    "data_dir = root_dir / \"docs/data\"\n",
    "for directory in [data_dir, img_dir, run_dir, datasets_dir]:\n",
    "    directory.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger(\"ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.exceptions import InconsistentVersionWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=InconsistentVersionWarning)\n",
    "\n",
    "infos = load_infos(run_dir)\n",
    "bi = basic_info = parse_basic_info(infos, main_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### For 2D datasets, for every clf & seeds\n",
    "#### Decision boundaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, clf = \"lunas_lo\", \"fkdc\"\n",
    "info, ds, tarea = decision_boundary(dataset, plotting_seed, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(mean_log_loss: pd.Series, logvero_base: float, n_eval: int) -> pd.Series:\n",
    "    return 1 - (mean_log_loss * n_eval) / logvero_base\n",
    "\n",
    "\n",
    "n_eval = len(tarea.y_eval)\n",
    "logvero_base = info[\"base\"].logvero\n",
    "assert 1 - info[clf].logvero / info[\"base\"].logvero == info[clf].r2\n",
    "pd.Series(info[clf].busqueda.cv_results_[\"mean_test_score\"]).apply(\n",
    "    R2, logvero_base=logvero_base, n_eval=n_eval\n",
    ").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_D2 = [\n",
    "    \"circulos_lo\",\n",
    "    \"circulos_hi\",\n",
    "    \"lunas_lo\",\n",
    "    \"lunas_hi\",\n",
    "    \"espirales_lo\",\n",
    "    \"espirales_hi\",\n",
    "    \"anteojos\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, clf in product(datasets_D2, clasificadores):\n",
    "    logger.debug([dataset, clf])\n",
    "    fig, ax = plt.subplots(layout=\"tight\")\n",
    "    decision_boundary(dataset, plotting_seed, clf, ax=ax)\n",
    "    fpath = img_dir / f\"{dataset}-{clf}-decision_boundary.svg\"\n",
    "    logger.info(fpath)\n",
    "    fig.savefig(fpath)\n",
    "    close(fig)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contourplot of score (loss?) surface\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = loss_contour(\n",
    "    \"espirales_lo\",\n",
    "    seed=run_seeds[10],\n",
    "    clf=\"fkdc\",\n",
    "    x=\"bandwidth\",\n",
    "    y=\"alpha\",\n",
    "    # other_params={\"weights\": \"uniform\"},\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "# TODO: loss in R^2 terms & clear color gradient\n",
    "ax = ret[1]\n",
    "ax.set_xscale(\"log\")\n",
    "# ret[1].set_xlim(1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = loss_contour(\n",
    "    \"espirales_lo\",\n",
    "    seed=run_seeds[5],\n",
    "    clf=\"fkn\",\n",
    "    x=\"n_neighbors\",\n",
    "    y=\"alpha\",\n",
    "    other_params={\"weights\": \"uniform\"},\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "# TODO: loss in R^2 terms & clear color gradient\n",
    "# ax.set_xscale(\"log\")\n",
    "# ret[1].set_xlim(1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, seed in product(datasets_D2, run_seeds):\n",
    "    logger.info([dataset, seed])\n",
    "    clf, x, y = \"fkdc\", \"bandwidth\", \"alpha\"\n",
    "    fig, ax, *_ = loss_contour(dataset, seed, clf, x, y)\n",
    "    ax.set_xscale(\"log\")\n",
    "    fpath = img_dir / f\"{dataset}-{seed}-{clf}-{x}-{y}-loss_contour.svg\"\n",
    "    logger.info(fpath)\n",
    "    fig.savefig(fpath)\n",
    "    close(fig)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, seed in product(datasets_D2, run_seeds):\n",
    "    logger.info([dataset, seed])\n",
    "    clf, x, y = \"fkn\", \"n_neighbors\", \"alpha\"\n",
    "    fig, ax, *_ = loss_contour(\n",
    "        dataset, seed, clf, x, y, other_params={\"weights\": \"uniform\"}\n",
    "    )\n",
    "    ax.set_xscale(\"log\")\n",
    "    fpath = img_dir / f\"{dataset}-{seed}-{clf}-{x}-{y}-loss_countour.svg\"\n",
    "    logger.info(fpath)\n",
    "    fig.savefig(fpath)\n",
    "    close(fig)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.de_fabrica(make_circles, n_samples=800, noise=0.05)\n",
    "sns.jointplot(x=ds.X[:, 0], y=ds.X[:, 1], hue=ds.y, legend=False)\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.savefig(img_dir / \"dos-circulos-jointplot.svg\")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = datasets_dir / f\"espirales_lo-{plotting_seed}.pkl\"\n",
    "with open(fpath, \"rb\") as fp:\n",
    "    ds = pickle.load(fp)\n",
    "sns.jointplot(x=ds.X[:, 0], y=ds.X[:, 1], hue=ds.y, legend=False)\n",
    "plt.xlim(-4, 4)\n",
    "plt.ylim(-4, 4)\n",
    "plt.savefig(img_dir / (fpath.stem + \"-jointplot.svg\"))\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"espirales_lo\"\n",
    "compare = \"fkn\"\n",
    "base = \"kn\"\n",
    "semillas_segun_delta_r2_desc = (\n",
    "    bi[bi.dataset.eq(dataset) & bi.clf.isin([compare, base])]\n",
    "    .set_index([\"semilla\", \"clf\"])\n",
    "    .r2.unstack()\n",
    "    .assign(delta_r2=lambda row: np.abs(row[compare] - row[base]))\n",
    "    .sort_values(\"delta_r2\", ascending=True)\n",
    "    .index.tolist()\n",
    ")\n",
    "mejores_semillas, peores_semillas = (\n",
    "    semillas_segun_delta_r2_desc[:3],\n",
    "    semillas_segun_delta_r2_desc[-3:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"helices_0\"\n",
    "\n",
    "infos_relevantes = {\n",
    "    k: pd.DataFrame(v[k[2]][\"busqueda\"].cv_results_)\n",
    "    for k, v in infos.items()\n",
    "    if k[0] == dataset and k[2].endswith(\"kdc\")\n",
    "}\n",
    "df = pd.concat(\n",
    "    infos_relevantes.values(),\n",
    "    keys=infos_relevantes.keys(),\n",
    "    names=(\"dataset\", \"seed\", \"clf\", \"main_seed\", \"scoring\", \"run\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators = {\n",
    "    k: v[k[2]][\"busqueda\"].best_estimator_\n",
    "    for k, v in infos.items()\n",
    "    if k[0] == dataset and k[2].endswith(\"kdc\")\n",
    "}\n",
    "best_params = [\n",
    "    {\n",
    "        \"clf\": k[2],\n",
    "        \"semilla\": int(k[1 if dataset in synth_datasets else 3]),\n",
    "        \"alpha\": v.get_params()[\"alpha\"],  # if k[2] == \"fkdc\" else 1,\n",
    "        \"bandwidth\": v.get_params()[\"bandwidth\"],\n",
    "    }\n",
    "    for k, v in best_estimators.items()\n",
    "]\n",
    "best_params = pd.DataFrame.from_records(best_params).set_index(\n",
    "    [\"semilla\", \"clf\"]\n",
    ")  # .unstack(\"clf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = (\n",
    "    bi[bi.dataset.eq(dataset) & bi.clf.str.endswith(\"kdc\")]\n",
    "    .set_index([\"semilla\", \"clf\"])\n",
    "    .r2\n",
    ")  # .unstack(\"clf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params[\"r2\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params.reset_index()[\n",
    "    [\"clf\", \"alpha\", \"bandwidth\"]\n",
    "].value_counts().sort_index().reset_index().round(4).to_csv(\n",
    "    data_dir / f\"{dataset}-best_params.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params.reset_index().groupby(\n",
    "    [\"clf\", \"alpha\", \"bandwidth\"]\n",
    ").r2.agg([\"count\", \"mean\", \"median\"]).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(layout=\"tight\")\n",
    "best_params[\"r2\"] = scores\n",
    "sns.scatterplot(best_params, x=\"bandwidth\", y=\"r2\", hue=\"clf\", ax=ax)\n",
    "fig.savefig(img_dir / f\"{dataset}-[f]kdc-r2-vs-bandwidth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi[bi.dataset.eq(dataset)].groupby(\"clf\").r2.median().round(4).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_seed = best_params.unstack(\"clf\").assign(\n",
    "    delta_h=lambda df: df.bandwidth.kdc.sub(df.bandwidth.fkdc),\n",
    "    delta_r2=lambda df: df.r2.kdc.sub(df.r2.fkdc),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(layout=\"tight\")\n",
    "sns.scatterplot(per_seed, x=\"delta_h\", y=\"delta_r2\")\n",
    "fig.savefig(img_dir / f\"{dataset}-[f]kdc-delta_r2-vs-delta_h.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params.groupby([\"clf\", \"bandwidth\"]).r2.agg(\"median\").reset_index().sort_values(\n",
    "    \"bandwidth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fkdc:\n",
    "  - 0.03162277660168379\n",
    "  - 0.05623413251903491\n",
    "  - 0.1\n",
    "  - 0.1778279410038923\n",
    "  - 0.31622776601683794\n",
    "  - 0.5623413251903491\n",
    "  - 1.0\n",
    "\n",
    "kdc:\n",
    "  - 0.055994858066093015\n",
    "  - 0.06755066513294422\n",
    "  - 0.08149127469020749\n",
    "  - 0.09830884473994828\n",
    "  - 0.11859710123376706\n",
    "  - 0.14307229891937587\n",
    "  - 0.17259850793256232\n",
    "  - 0.20821811885006605\n",
    "  - 0.25118864315095824\n",
    "  - 0.3030271082866399\n",
    "  - 0.36556361467894144\n",
    "  - 0.44100594541767413"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1.00000456 ** 5) / 1.00000456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    infos_relevantes.values(),\n",
    "    keys=infos_relevantes.keys(),\n",
    "    names=(\"dataset\", \"seed\", \"clf\", \"main_seed\", \"scoring\", \"run\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.xs(\"fkdc\", level=\"clf\").query(\"rank_test_score == 1\")[\n",
    "    [\"param_alpha\", \"param_bandwidth\"]\n",
    "].value_counts().reset_index().to_csv(\n",
    "    data_dir / \"lunas_lo-best_test_params.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D, low noise: lunas_lo, circulos_lo, espirales_lo\n",
    "d = 1, D = 2, k = 2, n = 800 con split 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = config.clasificadores.keys()\n",
    "tuple(clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"fkdc\", \"kdc\", \"gnb\", \"kn\", \"fkn\", \"lr\", \"slr\", \"svc\", \"gbt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, dataset, sufijo in product(\n",
    "    (\"accuracy\", \"r2\"), (\"lunas_lo\", \"circulos_lo\", \"espirales_lo\"), (\"kn\", \"kdc\")\n",
    "):\n",
    "    x = sufijo\n",
    "    y = f\"f{sufijo}\"\n",
    "    data = (\n",
    "        bi[bi.dataset.eq(dataset) & bi.clf.str.endswith(sufijo)]\n",
    "        .set_index([\"semilla\", \"clf\"])[metric]\n",
    "        .unstack()\n",
    "    )\n",
    "    fig, ax = plt.subplots(layout=\"tight\")\n",
    "    data.plot(kind=\"scatter\", y=y, x=x, ax=ax)\n",
    "    range = data.max().max() - data.min().min()\n",
    "    x_left = data.min()[x] - 0.1 * range\n",
    "    ax.set_xlim(x_left)\n",
    "    ax.set_ylim(data.min()[y] - 0.1 * range)\n",
    "    ax.axline((x_left, x_left), slope=1, color=\"gray\", linestyle=\"dotted\")\n",
    "    ax.set_title(f\"$R^2$ por semilla para {y} y {x} en `{dataset}`\")\n",
    "    fpath = img_dir / f\"{dataset}-{x}-{y}-{metric}-scatter.svg\"\n",
    "    logger.info(fpath)\n",
    "    fig.savefig(fpath)\n",
    "    close(fig)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [\"r2\", \"accuracy\"]:\n",
    "    best = (\n",
    "        bi.dropna(subset=metric)\n",
    "        .groupby([\"dataset\", \"clf\"])[metric]\n",
    "        .median()\n",
    "        .sort_values()\n",
    "        .reset_index(\"clf\")\n",
    "        .groupby(\"dataset\")\n",
    "        .last()\n",
    "        .clf.reset_index()\n",
    "        .groupby(\"clf\")\n",
    "        .agg([len, \", \".join])\n",
    "    )\n",
    "    best.columns = [\"cant\", \"datasets\"]\n",
    "    best.sort_values(\"cant\", ascending=False).to_csv(\n",
    "        open(data_dir / f\"mejor-clf-por-dataset-segun-{metric}-mediano.csv\", \"w\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi.clf.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi.dataset.nunique() * bi.clf.nunique() * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bi[bi.dataset.eq(\"helices_0\") & bi.clf.str.endswith(\"kn\")]\n",
    "    .set_index([\"semilla\", \"clf\"])\n",
    "    .r2.unstack(\"clf\")\n",
    "    .plot(x=\"kn\", y=\"fkn\", kind=\"scatter\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi[bi.dataset.eq(\"eslabones_0\") & bi.clf.str.endswith(\"kn\")].set_index(\n",
    "    [\"semilla\", \"clf\"]\n",
    ").r2.unstack().plot(kind=\"scatter\", y=\"fkn\", x=\"kn\")\n",
    "# .assign(delta=lambda df: df.fkn.sub(df.kn)).mul(100).round(2)\n",
    "plt.axline((0.5, 0.5), slope=1, color=\"gray\", linestyle=\"dotted\")\n",
    "plt.title(\"$R^2$ por semilla para FKN y KN en `eslabones_0`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        k[1:3]: info[k[2]].busqueda.best_estimator_.get_params()\n",
    "        for k, info in infos.items()\n",
    "        if k[0] == \"helices_0\" and k[2].endswith(\"kn\")\n",
    "    }\n",
    ").T[[\"alpha\", \"n_neighbors\"]].unstack().reorder_levels([1, 0], axis=1).sort_index(\n",
    "    axis=1\n",
    ").drop(columns=(\"kn\", \"alpha\"))  # .value_counts().reset_index().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        k[1:3]: info[k[2]].busqueda.best_estimator_.get_params()\n",
    "        for k, info in infos.items()\n",
    "        if k[0] == \"helices_0\" and k[2].endswith(\"kn\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detalle en espirales_lo, perfiles pérdida\n",
    "run_seed = 7060\n",
    "alpha = 2.25\n",
    "clave = (\"espirales_lo\", str(run_seed), \"fkdc\", str(main_seed), \"neg_log_loss\")\n",
    "orig_info = infos[clave]\n",
    "busqueda = pd.DataFrame(orig_info.fkdc.busqueda.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mean_test_scores = (\n",
    "    busqueda[busqueda.param_alpha == alpha].set_index(\"param_bandwidth\").mean_test_score\n",
    ")  # / len(info.fkdc.preds)\n",
    "orig_mean_test_scores.plot(figsize=(18, 5))\n",
    "plt.scatter(orig_mean_test_scores.index, orig_mean_test_scores)\n",
    "plt.xscale(\"symlog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "espirales_lo = Dataset.cargar(datasets_dir / f\"espirales_lo-{run_seed}.pkl\")\n",
    "espirales_lo.scatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fkdc.fermat import KDClassifier\n",
    "\n",
    "clf = KDClassifier(metric=\"fermat\", alpha=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarea = Tarea(\n",
    "    espirales_lo,\n",
    "    {\n",
    "        bandwidth: (clf, {\"bandwidth\": [bandwidth]})\n",
    "        for bandwidth in orig_mean_test_scores.index\n",
    "    },\n",
    "    seed=main_seed,\n",
    "    scoring=\"neg_log_loss\",\n",
    "    split_evaluacion=0.5,\n",
    ")\n",
    "tarea.entrenar()\n",
    "tarea.evaluar()\n",
    "new_info = tarea.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval = len(new_info[0.001].preds)\n",
    "new_metrics = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        bw: {\n",
    "            \"eval_logvero\": info.logvero,\n",
    "            \"eval_r2\": info.r2,\n",
    "            \"mean_test_score\": info.busqueda.cv_results_[\"mean_test_score\"][0],\n",
    "            \"std_test_score\": info.busqueda.cv_results_[\"std_test_score\"][0],\n",
    "            \"eval_accuracy\": info.accuracy,\n",
    "        }\n",
    "        for bw, info in new_info.items()\n",
    "        if bw != \"base\"\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "new_metrics[\"rank_test_score\"] = (-new_metrics.mean_test_score).rank().astype(int)\n",
    "# assert orig_mean_test_scores.equals(new_metrics.mean_test_score)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "new_metrics.eval_logvero.plot(label=\"eval\")\n",
    "new_metrics.mean_test_score.mul(n_eval).plot(label=\"test\")\n",
    "ax1.set_ylabel(\"logvero (solid lines)\")\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()\n",
    "new_metrics.eval_accuracy.plot(ax=ax2, linestyle=\"dotted\")\n",
    "ax2.set_ylabel(\"accuracy (dotted lines)\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score, sd = busqueda[busqueda.rank_test_score.eq(1)][\n",
    "    [\"mean_test_score\", \"std_test_score\"]\n",
    "].min()\n",
    "busqueda[busqueda.mean_test_score.ge(max_score - sd)].sort_values(\n",
    "    [\"param_alpha\", \"param_bandwidth\"], ascending=[True, False]\n",
    ")[\n",
    "    [\n",
    "        \"rank_test_score\",\n",
    "        \"param_alpha\",\n",
    "        \"param_bandwidth\",\n",
    "        \"mean_test_score\",\n",
    "        \"std_test_score\",\n",
    "        \"mean_train_score\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_max_score, new_sd = new_metrics[new_metrics.rank_test_score.eq(1)][\n",
    "    [\"mean_test_score\", \"std_test_score\"]\n",
    "].min()\n",
    "new_metrics[new_metrics.mean_test_score.ge(new_max_score - new_sd)].sort_index(\n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D, high noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "seed = run_seeds[0]\n",
    "datasets_2d = [\"lunas\", \"espirales\", \"circulos\"]\n",
    "for nombre, ax in zip(datasets_2d, axs, strict=False):\n",
    "    ds = pickle.load(open(datasets_dir / f\"{nombre}_hi-{seed}.pkl\", \"rb\"))\n",
    "    ds.scatter(ax=ax)\n",
    "    ax.set_title(nombre)\n",
    "plt.tight_layout()\n",
    "fig.savefig(img_dir / \"datasets-lunas-circulos-espirales-hi-new.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [ds for ds in bi.dataset.unique() if ds.endswith(\"_hi\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bi[bi.dataset.isin(datasets)]\n",
    "    .groupby([\"clf\", \"dataset\"])[[\"r2\", \"accuracy\"]]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .reorder_levels([1, 0], axis=1)\n",
    "    .sort_index(axis=1)\n",
    "    .sort_values((\"circulos_hi\", \"r2\"), ascending=False)\n",
    "    .mul(100)\n",
    "    .round(2)\n",
    ")\n",
    "# TBL 2: datsets 2d low noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R^2 consistentemente el mejor para (f)KDC, pero sin diferencias entre fermat y euclideo, pero muy jodido en gral\n",
    "- accuracy no mucho peor que SVC (que sigue siendo el rey)\n",
    "  - en lunas_hi gana FKDC!\n",
    "  - en circulos_hi, lunas_hi GBT competitivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "metric = \"r2\"\n",
    "for idx, dataset in enumerate(datasets):\n",
    "    ax = axs[idx]\n",
    "    data = bi[\n",
    "        bi.dataset.eq(dataset) & bi[metric].notna()\n",
    "    ].sort_values(\"clf\")\n",
    "    sns.boxplot(data, hue=\"clf\", y=metric, gap=0.2, ax=ax, palette=default_palette)\n",
    "    ax.set_title(dataset)\n",
    "    ax.axhline(\n",
    "        data.groupby(\"clf\")[metric].median().max(), linestyle=\"dotted\", color=\"gray\"\n",
    "    )\n",
    "    ybot, ytop = np.percentile(data[metric].dropna(), [25, 100])\n",
    "    ax.set_ylim(ybot * 0.99, ytop * 1.01)\n",
    "    if idx != 0:\n",
    "        ax.get_legend().set_visible(False)\n",
    "fig.tight_layout()\n",
    "fig.savefig(img_dir / \"boxplot-lunas-espirales-circulos-new.svg\")\n",
    "# IMG 2: Detalle metric boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi2d = bi[bi.dataset.str.endswith((\"_lo\", \"_hi\"))].copy()\n",
    "bi2d[[\"figura\", \"ruido\"]] = bi2d.dataset.str.split(\"_\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = (\n",
    "    bi2d.groupby([\"figura\", \"ruido\", \"clf\"])[[\"r2\", \"accuracy\"]]\n",
    "    .mean()\n",
    "    .unstack(\"ruido\")\n",
    "    \n",
    ")\n",
    "drops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for figura, metric in product(bi2d.figura.unique(), [\"r2\", \"accuracy\"]):\n",
    "    fig, ax = plt.subplots(layout=\"tight\")\n",
    "    (\n",
    "        drops.xs(figura)[metric][[\"lo\", \"hi\"]]\n",
    "        .sort_values(\"hi\", ascending=False)\n",
    "        .plot(kind=\"bar\", ax=ax)\n",
    "    )\n",
    "    plt.title(f\"Caída absoluta de {metric} en {figura}\")\n",
    "    fig.savefig(img_dir / f\"{figura}-caida_{metric}.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los órdenes se mantienen: quien andaba mejor en lo, anda mejor en hi, +- un cachito, pero los que _mejor_ andaban, más pierden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d, low dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "seed = run_seeds[0]  # 1134\n",
    "nombres_datasets = [\"pionono\", \"eslabones\", \"helices\", \"hueveras\"]\n",
    "\n",
    "datasets = {\n",
    "    nombre: pickle.load(open(datasets_dir / f\"{nombre}_0-{seed}.pkl\", \"rb\"))\n",
    "    for nombre in nombres_datasets\n",
    "}\n",
    "for idx, (nombre, ds) in enumerate(datasets.items(), start=1):\n",
    "    ax = fig.add_subplot(2, 2, idx, projection=\"3d\")\n",
    "    ds.scatter_3d(ax=ax)\n",
    "    ax.set_title(nombre)\n",
    "plt.tight_layout()\n",
    "fig.savefig(img_dir / \"datasets-3d-0.svg\")\n",
    "# IMG 2: datasets 2d, low noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "nombres_datasets = [\"pionono\", \"eslabones\", \"helices\", \"hueveras\"]\n",
    "\n",
    "datasets = {\n",
    "    nombre: pickle.load(open(datasets_dir / f\"{nombre}_0-{plotting_seed}.pkl\", \"rb\"))\n",
    "    for nombre in nombres_datasets\n",
    "}\n",
    "for nombre, ds in datasets.items():\n",
    "    fig, ax = plt.subplots(layout=\"tight\", subplot_kw={'projection': '3d'})\n",
    "    ds.scatter_3d(ax=ax)\n",
    "    ax.set_title(nombre)\n",
    "    fpath = img_dir / f\"{nombre}-scatter-3d.svg\"\n",
    "    logger.debug(fpath)\n",
    "    fig.savefig(fpath)\n",
    "    close(fig)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre, ds in datasets.items():\n",
    "    ds.pairplot(dims=[2, 1, 0], height=2, plot_kws={\"alpha\": 0.5, \"s\": 5}, corner=True)\n",
    "    plt.suptitle(nombre)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bi[bi.dataset.isin(f\"{nombre}_0\" for nombre in nombres_datasets)]\n",
    "    .groupby([\"clf\", \"dataset\"])[[\"r2\", \"accuracy\"]]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .reorder_levels([1, 0], 1)\n",
    "    .sort_index(axis=1)\n",
    "    .mul(100)\n",
    "    .round(2)\n",
    "    .sort_values((\"pionono_0\", \"r2\"), ascending=False)\n",
    ")  # TBL 2: datsets 2d low noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- helices y eslabones muy fáciles\n",
    "- en heveras a fKDC le duele la varianza agregada versus eKDC\n",
    "- (f)KDC best in class for acc & r2 (acc like SVC, plus R^2), but mostly no diff\n",
    "  - r^2 empeora algo en helices con fkdc, sigue siendo mucho mejor que (f)KN, resto ni computa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "metric = \"r2\"\n",
    "for (idx, nombre), ax in zip(enumerate(nombres_datasets), axs.flatten(), strict=False):\n",
    "    data = bi[\n",
    "        bi.dataset.eq(f\"{nombre}_0\") & ~bi.clf.isin(exclude_clfs) & bi[metric].notna()\n",
    "    ].sort_values(\"clf\")\n",
    "    sns.boxplot(data, hue=\"clf\", y=metric, gap=0.2, ax=ax, palette=default_palette)\n",
    "    ax.set_title(nombre)\n",
    "    ax.axhline(\n",
    "        data.groupby(\"clf\")[metric].median().max(), linestyle=\"dotted\", color=\"gray\"\n",
    "    )\n",
    "    ybot, ytop = np.percentile(data[metric].dropna(), [40, 100])\n",
    "    ax.set_ylim(ybot, None)\n",
    "    if idx != 0:\n",
    "        ax.get_legend().set_visible(False)\n",
    "fig.tight_layout()\n",
    "fig.savefig(img_dir / \"3d-low-r2.svg\")\n",
    "# IMG 2: Detalle metric boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clave_fkdc = (\"pionono_0\", str(run_seeds[6]), \"fkdc\", str(main_seed), \"neg_log_loss\")\n",
    "clave_kdc = (\"pionono_0\", str(run_seeds[6]), \"kdc\", str(main_seed), \"neg_log_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algún comentario sobre pionono de sapienza???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d, high dim\n",
    "- no hace falta reproducir, pues el resto son puro ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "seed = run_seeds[0]  # 1134\n",
    "nombres_datasets = [\"pionono\", \"eslabones\", \"helices\", \"hueveras\"]\n",
    "\n",
    "datasets = {\n",
    "    nombre: pickle.load(open(datasets_dir / f\"{nombre}_12-{seed}.pkl\", \"rb\"))\n",
    "    for nombre in nombres_datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre, ds in datasets.items():\n",
    "    ds.pairplot(dims=[3, 4, 5], height=2, plot_kws={\"alpha\": 0.5, \"s\": 5}, corner=True)\n",
    "    plt.suptitle(nombre)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bi[bi.dataset.isin(f\"{nombre}_12\" for nombre in nombres_datasets)]\n",
    "    .groupby([\"clf\", \"dataset\"])[[\"r2\", \"accuracy\"]]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .reorder_levels([1, 0], 1)\n",
    "    .sort_index(axis=1)\n",
    "    .mul(100)\n",
    "    .round(2)\n",
    "    .sort_values((\"eslabones_12\", \"accuracy\"), ascending=False)\n",
    ")  # TBL 2: datsets 2d low noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- eslabones: (f)[kdc|kn] _zafan_ contra svc,, pero pierden con gnb y gbt brillan:\n",
    "  - gnb: las dimensioens de ruido le duelen muy poquito, pues todo es independiente\n",
    "  - gbt: bien noparam, puede \"ignorar\" fácilmente las dimensioens extra\n",
    "Una manera de verlo: generic feature importances (permutation importance)\n",
    "\n",
    "- helices, hueveras: muy dificiles para todos (en acc y r2), pero (f)kdc encima dan r^2 _negativo_, con confianza le erran\n",
    "- NO parece culpa de fermat: en fkn vs kn, r^2 da igualito\n",
    "  - interesante: por qué el r^2 de kcd es tanto peor que el de fkdc en hueveras?\n",
    "\n",
    "- pionono: gbt brilla+, gnb brilla, resto malísimo: acá de hecho LR anda mejor que (f)[kdc|kn]\n",
    "\n",
    "LA MALDICIÓN DE LA DIMENSIONALIDAD SIGUE JODIENDO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = \"pionono_12\"\n",
    "semilla = 7060\n",
    "ds = Dataset.cargar(datasets_dir / f\"{nombre}-{semilla}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps = {}\n",
    "for clf in clasificadores.keys():\n",
    "    logger.info(f\"Processing permutation importance for {clf}\")\n",
    "    scoring = \"neg_log_loss\" if clf != \"svc\" else \"accuracy\"\n",
    "    info = infos[(nombre, str(semilla), clf, str(main_seed), scoring)]\n",
    "    best = info[clf].busqueda.best_estimator_\n",
    "    importances = permutation_importance(best, ds.X, ds.y, scoring=scoring)\n",
    "    imps[clf] = importances[\"importances_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps = pd.DataFrame(imps)\n",
    "imps[[\"fkdc\", \"gbt\", \"svc\", \"gnb\"]].loc[:5].plot(kind=\"bar\", color=default_palette)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "metric = \"r2\"\n",
    "for (idx, nombre), ax in zip(enumerate(nombres_datasets), axs.flatten(), strict=False):\n",
    "    data = bi[\n",
    "        bi.dataset.eq(f\"{nombre}_12\") & ~bi.clf.isin(exclude_clfs) & bi[metric].notna()\n",
    "    ].sort_values(\"clf\")\n",
    "    sns.boxplot(data, hue=\"clf\", y=metric, gap=0.2, ax=ax, palette=default_palette)\n",
    "    ax.set_title(nombre)\n",
    "    ax.axhline(\n",
    "        data.groupby(\"clf\")[metric].median().max(), linestyle=\"dotted\", color=\"gray\"\n",
    "    )\n",
    "    ybot, ytop = np.percentile(data[metric].dropna(), [10, 100])\n",
    "    ax.set_ylim(ybot, None)\n",
    "    if idx != 0:\n",
    "        ax.get_legend().set_visible(False)\n",
    "fig.tight_layout()\n",
    "fig.savefig(img_dir / \"3d-low-r2.svg\")\n",
    "# IMG 2: Detalle metric boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2s = bi[bi.dataset.eq(\"hueveras_12\")].set_index([\"semilla\", \"clf\"]).r2.unstack()\n",
    "r2s[[\"fkn\", \"kn\"]].plot(kind=\"bar\")\n",
    "# ínfima diferencia, pero en genral pareja p/ambos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-r2s[[\"fkdc\", \"kdc\"]]).plot(kind=\"bar\")\n",
    "# mucha diferencia, siempre en contra de KDC. los best params?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = \"hueveras_12\"\n",
    "clf = \"fkdc\"\n",
    "scoring = \"neg_log_loss\" if clf != \"svc\" else \"accuracy\"\n",
    "info = infos[(nombre, str(semilla), clf, str(main_seed), scoring)][clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda = pd.DataFrame(info.busqueda.cv_results_)\n",
    "data = busqueda.set_index([\"param_alpha\", \"param_bandwidth\"]).mean_test_score.unstack()\n",
    "X = data.columns.values\n",
    "Y = data.index.values\n",
    "Z = data.values\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "zmin, zmax = Z.min(), Z.max()\n",
    "CS = ax.contourf(X, Y, Z, 15, cmap=\"viridis\")\n",
    "# CS = ax.contour(X, Y, Z, 15, cmap=\"viridis\")\n",
    "ax.set_title(\"Exactitud para $\\\\alpha$ y $h$\")\n",
    "ax.set_xlabel(\"$h$\")\n",
    "ax.set_ylabel(\"$\\\\alpha$\")\n",
    "ax.scatter(X[Z.argmax(axis=1)], Y, marker=\"x\", color=\"red\")\n",
    "# Make a colorbar for the ContourSet returned by the contourf call.\n",
    "cbar = fig.colorbar(CS)\n",
    "cbar.ax.set_ylabel(\"Exactitud\")\n",
    "ax.set_xscale(\"log\")\n",
    "# plt.tight_layout()\n",
    "fig.savefig(img_dir / \"heatmap-fkdc-2d-lo-new.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "da todo igual!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = \"hueveras_12\"\n",
    "clf = \"kdc\"\n",
    "scoring = \"neg_log_loss\" if clf != \"svc\" else \"accuracy\"\n",
    "info = infos[(nombre, str(semilla), clf, str(main_seed), scoring)][clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda = pd.DataFrame(info.busqueda.cv_results_)\n",
    "busqueda.set_index(\"param_bandwidth\")[\n",
    "    [\n",
    "        \"mean_test_score\",\n",
    "        \"mean_train_score\",\n",
    "    ]\n",
    "].plot()\n",
    "plt.axvline(info.busqueda.best_estimator_.bandwidth, color=\"gray\", linestyle=\"dotted\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pipo"
    ]
   },
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        pd.DataFrame.from_dict(\n",
    "            {\n",
    "                k[1]: v.fkdc.busqueda.best_params_\n",
    "                for k, v in infos.items()\n",
    "                if k[0] == \"hueveras_12\" and k[2] == \"fkdc\"\n",
    "            },\n",
    "            orient=\"index\",\n",
    "        ).add_prefix(\"fkdc_\"),\n",
    "        pd.DataFrame.from_dict(\n",
    "            {\n",
    "                k[1]: v.kdc.busqueda.best_params_\n",
    "                for k, v in infos.items()\n",
    "                if k[0] == \"hueveras_12\" and k[2] == \"kdc\"\n",
    "            },\n",
    "            orient=\"index\",\n",
    "        ).add_prefix(\"kdc_\"),\n",
    "        bi[bi.clf.str.endswith(\"kdc\") & bi.dataset.eq(\"hueveras_12\")]\n",
    "        .assign(semilla=lambda df: df.semilla.astype(str))\n",
    "        .set_index([\"semilla\", \"clf\"])\n",
    "        .r2.mul(10000)\n",
    "        .astype(int)\n",
    "        .unstack()\n",
    "        .add_suffix(\"_logvero\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ").sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los dos estimadores están contra los \"bordes\" de su caja de hiperparámetros, y el paisaje/superficie de pérdida es súper plana, la diferencia es que por alguna razón fkdc paró mejor en el borde de máxima parsimonia (1, 100), mientras que kdc encontró mínimas diferencias numéricas y está agarrando \"óptimos\" muy chiquitos que son marginalmente mejores que 10K (y cuando lo agarra, da simplemente 0 el R^2). \n",
    "\n",
    "Otro caso más para empujar una regla tipo 1SD rule arriba del refit parsimonioso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi3d = bi[bi.dataset.str.endswith((\"_0\", \"_12\"))].copy()\n",
    "bi3d[[\"figura\", \"dims_ruido\"]] = bi3d.dataset.str.split(\"_\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"accuracy\"\n",
    "drops = (\n",
    "    bi3d.groupby([\"figura\", \"dims_ruido\", \"clf\"])[[\"r2\", \"accuracy\"]]\n",
    "    .mean()[metric]\n",
    "    .unstack(\"dims_ruido\")\n",
    "    .assign(rel_drop=lambda df: (df[\"0\"] - df[\"12\"]).div(df[\"0\"]))\n",
    ")\n",
    "drops.rel_drop.unstack(\"figura\").dropna().mul(100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for figura in bi3d.figura.unique():\n",
    "    (\n",
    "        drops.xs(figura)\n",
    "        .drop(columns=\"rel_drop\")[[\"0\", \"12\"]]\n",
    "        .sort_values(\"12\", ascending=False)\n",
    "        .plot(kind=\"bar\")\n",
    "    )\n",
    "    plt.title(f\"Caída absoluta de {metric} en {figura}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "datasets_multik = [\"anteojos\", \"iris\", \"vino\", \"pinguinos\"]\n",
    "for nombre, ax in zip(datasets_multik, axs.flatten(), strict=False):\n",
    "    ds = pickle.load(open(datasets_dir / f\"{nombre}.pkl\", \"rb\"))\n",
    "    ds.scatter(ax=ax)\n",
    "    ax.set_title(f\"{nombre} (n={ds.n}; p={ds.p}, k={ds.k})\")\n",
    "plt.tight_layout()\n",
    "# fig.savefig(img_dir / \"datasets-lunas-circulos-espirales-hi-new.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bi[bi.dataset.isin(datasets_multik)]\n",
    "    .groupby([\"clf\", \"dataset\"])[[\"r2\", \"accuracy\"]]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .reorder_levels([1, 0], axis=1)\n",
    "    .sort_index(axis=1)\n",
    "    .sort_values((\"iris\", \"r2\"), ascending=False)\n",
    "    .mul(100)\n",
    "    .round(2)\n",
    ")\n",
    "# TBL 2: datsets 2d low noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anteojos\n",
    "espectacular performance de fKDC en R2, con acc ==SVC, pero a esta altura es imposible encontrar una diferencia entre ambos, clarito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_dataset = \"anteojos\"\n",
    "seed = 1434\n",
    "# clfs = [\"fkdc\", \"kdc\", \"kn\", \"fkn\", \"gbt\", \"lr\", \"slr\", \"gnb\", \"svc\"]\n",
    "clfs = basic_info.clf.unique().tolist()\n",
    "dataset = pickle.load(open(datasets_dir / f\"{nombre_dataset}.pkl\", \"rb\"))\n",
    "# dataset = pickle.load(open(datasets_dir / f\"{nombre_dataset}-{seed}.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarea = Tarea(dataset, {}, seed=seed, split_evaluacion=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Iris\n",
    "Acc esta OK, pero R2 sufre bocha en el promedio por algunas muy malas semillas que llevan el R2 a terreno negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi[bi.clf.str.endswith(\"kdc\") & bi.dataset.eq(\"iris\")].pivot(\n",
    "    index=\"semilla\", columns=\"clf\", values=\"r2\"\n",
    ").sort_values(\"fkdc\").plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_seed = 1182\n",
    "clf = \"fkdc\"\n",
    "clave = (\"iris\", str(None), clf, str(bad_seed), \"neg_log_loss\")\n",
    "info = infos[clave][clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda = pd.DataFrame(info.busqueda.cv_results_)\n",
    "data = busqueda.set_index([\"param_alpha\", \"param_bandwidth\"]).mean_test_score.unstack()\n",
    "X = data.columns.values\n",
    "Y = data.index.values\n",
    "Z = data.values\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "zmin, zmax = Z.min(), Z.max()\n",
    "CS = ax.contourf(X, Y, Z, 15, cmap=\"viridis\")\n",
    "# CS = ax.contour(X, Y, Z, 15, cmap=\"viridis\")\n",
    "ax.set_title(\"Exactitud para $\\\\alpha$ y $h$\")\n",
    "ax.set_xlabel(\"$h$\")\n",
    "ax.set_ylabel(\"$\\\\alpha$\")\n",
    "ax.scatter(X[Z.argmax(axis=1)], Y, marker=\"x\", color=\"red\")\n",
    "# Make a colorbar for the ContourSet returned by the contourf call.\n",
    "cbar = fig.colorbar(CS)\n",
    "cbar.ax.set_ylabel(\"Exactitud\")\n",
    "ax.set_xscale(\"log\")\n",
    "# plt.tight_layout()\n",
    "fig.savefig(img_dir / \"heatmap-fkdc-2d-lo-new.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_seed = 5640\n",
    "clf = \"fkdc\"\n",
    "clave = (\"iris\", str(None), clf, str(bad_seed), \"neg_log_loss\")\n",
    "info = infos[clave][clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda = pd.DataFrame(info.busqueda.cv_results_)\n",
    "data = busqueda.set_index([\"param_alpha\", \"param_bandwidth\"]).mean_test_score.unstack()\n",
    "X = data.columns.values\n",
    "Y = data.index.values\n",
    "Z = data.values\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "zmin, zmax = Z.min(), Z.max()\n",
    "CS = ax.contourf(X, Y, Z, 15, cmap=\"viridis\")\n",
    "# CS = ax.contour(X, Y, Z, 15, cmap=\"viridis\")\n",
    "ax.set_title(\"Exactitud para $\\\\alpha$ y $h$\")\n",
    "ax.set_xlabel(\"$h$\")\n",
    "ax.set_ylabel(\"$\\\\alpha$\")\n",
    "ax.scatter(X[Z.argmax(axis=1)], Y, marker=\"x\", color=\"red\")\n",
    "# Make a colorbar for the ContourSet returned by the contourf call.\n",
    "cbar = fig.colorbar(CS)\n",
    "cbar.ax.set_ylabel(\"Exactitud\")\n",
    "ax.set_xscale(\"log\")\n",
    "# plt.tight_layout()\n",
    "# fig.savefig(img_dir / \"heatmap-fkdc-2d-lo-new.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = \"iris\"\n",
    "clf = \"kdc\"\n",
    "scoring = \"neg_log_loss\" if clf != \"svc\" else \"accuracy\"\n",
    "# seeds = [1134, 3923, 6825, 4505]  # good, bad, bad, good\n",
    "seeds = _get_run_seeds()[:4]\n",
    "height = 5\n",
    "fig, axs = plt.subplots(1, len(seeds), figsize=(height * len(seeds), height))\n",
    "for seed, ax in zip(seeds, axs, strict=False):\n",
    "    info = infos[(nombre, str(None), clf, str(seed), scoring)][clf]\n",
    "    busqueda = pd.DataFrame(info.busqueda.cv_results_)\n",
    "    busqueda.set_index(\"param_bandwidth\")[\n",
    "        [\n",
    "            \"mean_test_score\",\n",
    "            \"mean_train_score\",\n",
    "        ]\n",
    "    ].plot(ax=ax)\n",
    "    ax.set_title(f\"{seed}\")\n",
    "    ax.axvline(\n",
    "        info.busqueda.best_estimator_.bandwidth, color=\"gray\", linestyle=\"dotted\"\n",
    "    )\n",
    "    ax.axhline(info.logvero / len(info.preds), color=\"C2\", label=\"mean_eval_score\")\n",
    "    ax.legend()\n",
    "    ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "metric = \"r2\"\n",
    "for idx, dataset in enumerate(datasets_multik):\n",
    "    ax = axs.flatten()[idx]\n",
    "    data = bi[\n",
    "        bi.dataset.eq(dataset) & ~bi.clf.isin(exclude_clfs) & bi[metric].notna()\n",
    "    ].sort_values(\"clf\")\n",
    "    sns.boxplot(data, hue=\"clf\", y=metric, gap=0.2, ax=ax, palette=default_palette)\n",
    "    ax.set_title(dataset)\n",
    "    ax.axhline(\n",
    "        data.groupby(\"clf\")[metric].median().max(), linestyle=\"dotted\", color=\"gray\"\n",
    "    )\n",
    "    # ybot, ytop = np.percentile(data[metric].dropna(), [25, 100])\n",
    "    # ax.set_ylim(ybot * 0.99, ytop * 1.01)\n",
    "    if idx != 0:\n",
    "        ax.get_legend().set_visible(False)\n",
    "fig.tight_layout()\n",
    "# fig.savefig(img_dir / \"boxplot-lunas-espirales-circulos-new.svg\")\n",
    "# IMG 2: Detalle metric boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_seed = 5640\n",
    "clf = \"fkdc\"\n",
    "clave = (\"vino\", str(None), clf, str(bad_seed), \"neg_log_loss\")\n",
    "info = infos[clave][clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda = pd.DataFrame(info.busqueda.cv_results_)\n",
    "data = busqueda.set_index([\"param_alpha\", \"param_bandwidth\"]).mean_test_score.unstack()\n",
    "X = data.columns.values\n",
    "Y = data.index.values\n",
    "Z = data.values\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "zmin, zmax = Z.min(), Z.max()\n",
    "CS = ax.contourf(X, Y, Z, 15, cmap=\"viridis\")\n",
    "# CS = ax.contour(X, Y, Z, 15, cmap=\"viridis\")\n",
    "ax.set_title(\"Exactitud para $\\\\alpha$ y $h$\")\n",
    "ax.set_xlabel(\"$h$\")\n",
    "ax.set_ylabel(\"$\\\\alpha$\")\n",
    "ax.scatter(X[Z.argmax(axis=1)], Y, marker=\"x\", color=\"red\")\n",
    "# Make a colorbar for the ContourSet returned by the contourf call.\n",
    "cbar = fig.colorbar(CS)\n",
    "cbar.ax.set_ylabel(\"Exactitud\")\n",
    "ax.set_xscale(\"log\")\n",
    "# plt.tight_layout()\n",
    "fig.savefig(img_dir / \"heatmap-fkdc-2d-lo-new.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = \"iris\"\n",
    "clf_metrics = {\"kdc\": \"bandwidth\", \"gnb\": \"var_smoothing\"}\n",
    "scoring = \"neg_log_loss\" if clf != \"svc\" else \"accuracy\"\n",
    "seed = 1182\n",
    "height = 5\n",
    "fig, axs = plt.subplots(1, 2, figsize=(height * len(clf_metrics), height))\n",
    "for (clf, metric), ax in zip(clf_metrics.items(), axs, strict=False):\n",
    "    info = infos[(nombre, str(None), clf, str(seed), scoring)][clf]\n",
    "    busqueda = pd.DataFrame(info.busqueda.cv_results_)\n",
    "    busqueda.set_index(f\"param_{metric}\")[\n",
    "        [\n",
    "            \"mean_test_score\",\n",
    "            \"mean_train_score\",\n",
    "        ]\n",
    "    ].plot(ax=ax)\n",
    "    ax.set_title(f\"{clf} by {metric}\")\n",
    "    ax.axvline(\n",
    "        getattr(info.busqueda.best_estimator_, metric), color=\"gray\", linestyle=\"dotted\"\n",
    "    )\n",
    "    ax.axhline(info.logvero / len(info.preds), color=\"C2\", label=\"mean_eval_score\")\n",
    "    ax.legend()\n",
    "    ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pinguinos\n",
    "OK, pongámosle que en `iris` (f)KDC da tan mal porque tuvimos mala suerte con las semillas, una regla más parsimoniosa hubiese ayudado. Pero en `iris`, da _todo_ mal (\"peor\"); por qué? Tiene 3 clases fácilmente diferenciables a ojo en el eje `(0, 1)`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinguinos = pickle.load(open(datasets_dir / \"pinguinos.pkl\", \"rb\"))\n",
    "pinguinos.pairplot(height=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, en el eje `(0, 1)` (o `(0, 2)`, o `(0, 3)`) las tres clases son fácilmente diferenciables a ojo, pero en las dims `(1,2,3)` Adelie y Chinstrap están muy encimadas. ¿Será que funcionan como \"dimensiones de ruido\" y confunden al clasificador más de lo que lo ayudan?\n",
    "Si así fuese, esperaríamos ver que en la matriz de confusión, \"Gentoo\" aparece bien clasificada, y \"Adelie/Chinstrap\" están confundidas. Si así fuese,\n",
    "\n",
    "1. La matriz de confusión debería verse \"diagonal por bloques\", y\n",
    "2. Reentrenar el clasificador (digamos que KDC para simplificar) con sólo dos dimensiones debería mejorar la performance.\n",
    "\n",
    "Veamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_semilla = (\n",
    "    bi[bi.dataset.eq(\"pinguinos\") & bi.clf.eq(\"kdc\")]\n",
    "    .sort_values(\"r2\", ascending=False)\n",
    "    .iloc[0]\n",
    "    .semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarea_pinguinos = Tarea(\n",
    "    pinguinos, algoritmos={}, seed=mejor_semilla, split_evaluacion=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clave = (\"pinguinos\", \"None\", \"kdc\", str(mejor_semilla), \"neg_log_loss\")\n",
    "info = infos[clave].kdc\n",
    "mejor_kdc = info.busqueda.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "expected_accuracy = info.accuracy\n",
    "y_true = tarea_pinguinos.y_eval\n",
    "y_pred = mejor_kdc.predict(tarea_pinguinos.X_eval)\n",
    "actual_accuracy = accuracy_score(y_true, y_pred)\n",
    "assert actual_accuracy == expected_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"true\": y_true, \"pred\": y_pred}).value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"eval\": pd.Series(y_true).value_counts(normalize=True),\n",
    "        \"pop\": pd.Series(ds.y).value_counts(normalize=True),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente, Gentoo y Adelie están esencialmente bien clasificados, pero la clase Chinstrap está completamente predicha como Adelie, que es la clase mayoritaria en su cluster.\n",
    "Las proporciones son muy similares en evaluación que en la población en general, también."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinguinos_corto = Dataset(pinguinos.X[:, [0, 1]], pinguinos.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KDClassifier(metric=\"euclidean\")\n",
    "tarea = Tarea(\n",
    "    pinguinos_corto,\n",
    "    {\"kdc\": (clasificadores[\"kdc\"], grillas[\"kdc\"])},\n",
    "    seed=mejor_semilla,\n",
    "    scoring=\"neg_log_loss\",\n",
    "    split_evaluacion=0.5,\n",
    ")\n",
    "tarea.entrenar()\n",
    "tarea.evaluar()\n",
    "pinguinos_corto_info = tarea.info\n",
    "n_eval = len(tarea.y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.accuracy, tarea.info[\"kdc\"].accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.r2, tarea.info[\"kdc\"].r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.DataFrame(\n",
    "    {\n",
    "        \"true\": tarea.y_eval,\n",
    "        \"orig_pred\": y_pred,\n",
    "        \"new_pred\": tarea.info.kdc.busqueda.best_estimator_.predict(tarea.X_eval),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp[[\"true\", \"orig_pred\"]].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp[[\"true\", \"new_pred\"]].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Increíble! Debería repetirse similarmente para `vino`. E examinar el pairplot, sabemos que de las 13 dimesiones, `(6, 9, 12)` son bastante difenretes de a pares:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vino = pickle.load(open(datasets_dir / \"vino.pkl\", \"rb\"))\n",
    "vino.pairplot(dims=[6, 9, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_semilla = (\n",
    "    bi[bi.dataset.eq(\"vino\") & bi.clf.eq(\"kdc\")]\n",
    "    .sort_values(\"accuracy\", ascending=False)\n",
    "    .iloc[0]\n",
    "    .semilla\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarea_vino = Tarea(vino, algoritmos={}, seed=mejor_semilla, split_evaluacion=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clave = (\"vino\", \"None\", \"kdc\", str(mejor_semilla), \"neg_log_loss\")\n",
    "info = infos[clave].kdc\n",
    "mejor_kdc = info.busqueda.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "expected_accuracy = info.accuracy\n",
    "y_true = tarea_vino.y_eval\n",
    "y_pred = mejor_kdc.predict(tarea_vino.X_eval)\n",
    "actual_accuracy = accuracy_score(y_true, y_pred)\n",
    "assert actual_accuracy == expected_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"true\": y_true, \"pred\": y_pred}).value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"eval\": pd.Series(y_true).value_counts(normalize=True),\n",
    "        \"pop\": pd.Series(vino.y).value_counts(normalize=True),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vino_corto = Dataset(vino.X[:, [6, 9, 12]], vino.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KDClassifier(metric=\"euclidean\")\n",
    "tarea = Tarea(\n",
    "    vino_corto,\n",
    "    {\"kdc\": (clasificadores[\"kdc\"], grillas[\"kdc\"])},\n",
    "    seed=mejor_semilla,\n",
    "    scoring=\"neg_log_loss\",\n",
    ")\n",
    "tarea.entrenar()\n",
    "tarea.evaluar()\n",
    "vino_corto_info = tarea.info\n",
    "n_eval = len(tarea.y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.accuracy, tarea.info[\"kdc\"].accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.r2, tarea.info[\"kdc\"].r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.DataFrame(\n",
    "    {\n",
    "        \"true\": tarea.y_eval,\n",
    "        \"orig_pred\": y_pred,\n",
    "        \"new_pred\": tarea.info.kdc.busqueda.best_estimator_.predict(tarea.X_eval),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp[[\"true\", \"orig_pred\"]].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp[[\"true\", \"new_pred\"]].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejor, pero no _mucho_ mejor. Evidentemente hay más cosas a examinar..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bi[bi.dataset.isin([\"digitos\", \"mnist\"])]\n",
    "    .groupby([\"clf\", \"dataset\"])[[\"r2\", \"accuracy\"]]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .reorder_levels([1, 0], axis=1)\n",
    "    .sort_index(axis=1)\n",
    "    .sort_values((\"mnist\", \"accuracy\"), ascending=False)\n",
    "    .mul(100)\n",
    "    .round(2)\n",
    ")\n",
    "# TBL 2: datsets 2d low noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### digitos\n",
    "bomba! aunque tambien andan muy bien todos, hasta LR tiene excelente acc yR2; GNB pifia en R2 pero still competitivo y los tiempos deben ser minimos\n",
    "TODO: mirar tiempos, maybe su propia sección\n",
    "\n",
    "#### mnist\n",
    "curioso: KDC super competitivo, fKDC un desastre. analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        pd.DataFrame.from_dict(\n",
    "            {\n",
    "                k[1]: v.fkdc.busqueda.best_params_\n",
    "                for k, v in infos.items()\n",
    "                if k[0] == \"mnist\" and k[2] == \"fkdc\"\n",
    "            },\n",
    "            orient=\"index\",\n",
    "        ).add_prefix(\"fkdc_\"),\n",
    "        pd.DataFrame.from_dict(\n",
    "            {\n",
    "                k[1]: v.kdc.busqueda.best_params_\n",
    "                for k, v in infos.items()\n",
    "                if k[0] == \"mnist\" and k[2] == \"kdc\"\n",
    "            },\n",
    "            orient=\"index\",\n",
    "        ).add_prefix(\"kdc_\"),\n",
    "        bi[bi.clf.str.endswith(\"kdc\") & bi.dataset.eq(\"mnist\")]\n",
    "        .assign(semilla=lambda df: df.semilla.astype(str))\n",
    "        .set_index([\"semilla\", \"clf\"])\n",
    "        .r2.mul(10000)\n",
    "        .astype(int)\n",
    "        .unstack()\n",
    "        .add_suffix(\"_logvero\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ").sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grillas[\"fkdc\"][\"bandwidth\"].max(), grillas[\"kdc\"][\"bandwidth\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(run_seed)\n",
    "mnist_ds = Dataset.cargar(datasets_dir / f\"mnist-{run_seed}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_ds.X.min(), mnist_ds.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 96\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_components = n_components / X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(ratio_components).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(infos.keys())[:5]\n",
    "best_params = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"seed\": int(main_seed if run_seed == \"None\" else run_seed),\n",
    "            \"clf\": clf,\n",
    "            \"ds\": ds,\n",
    "            \"best_params\": [\n",
    "                {\"param\": key, \"value\": value}\n",
    "                for key, value in info[clf].busqueda.best_params_.items()\n",
    "            ],\n",
    "        }\n",
    "        for (ds, run_seed, clf, main_seed, _), info in infos.items()\n",
    "        if clf.endswith(\"kdc\")\n",
    "    ]\n",
    ").set_index([\"seed\", \"clf\", \"ds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = best_params.index\n",
    "data = best_params.explode(\"best_params\")\n",
    "best_params = (\n",
    "    pd.DataFrame.from_records(data.best_params.values, index=data.index)\n",
    "    .pivot(columns=\"param\", values=\"value\")\n",
    "    .unstack(\"clf\")\n",
    "    .reorder_levels(order=[1, 0], axis=1)\n",
    "    .sort_index(axis=1)\n",
    "    .sort_index(level=\"ds\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params.xs(\"helices_12\", level=\"ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = \"helices_12\"\n",
    "clf_metrics = {\"kdc\": \"bandwidth\", \"gnb\": \"var_smoothing\"}\n",
    "scoring = \"neg_log_loss\" if clf != \"svc\" else \"accuracy\"\n",
    "seed = run_seed  # 3031\n",
    "height = 5\n",
    "fig, axs = plt.subplots(1, 2, figsize=(height * len(clf_metrics), height))\n",
    "for (clf, metric), ax in zip(clf_metrics.items(), axs, strict=False):\n",
    "    info = infos[(nombre, str(seed), clf, str(main_seed), scoring)][clf]\n",
    "    # info = infos[(nombre, str(None), clf, str(seed), scoring)][clf]\n",
    "    busqueda = pd.DataFrame(info.busqueda.cv_results_)\n",
    "    busqueda.set_index(f\"param_{metric}\")[\n",
    "        [\n",
    "            \"mean_test_score\",\n",
    "            \"mean_train_score\",\n",
    "        ]\n",
    "    ].plot(ax=ax)\n",
    "    ax.set_title(f\"{clf} by {metric}\")\n",
    "    ax.axvline(\n",
    "        getattr(info.busqueda.best_estimator_, metric), color=\"gray\", linestyle=\"dotted\"\n",
    "    )\n",
    "    ax.axhline(info.logvero / len(info.preds), color=\"C2\", label=\"mean_eval_score\")\n",
    "    ax.legend()\n",
    "    ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificadores[\"gnb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grillas[\"gnb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = KDClassifier(metric=\"euclidean\")\n",
    "clf = GaussianNB()\n",
    "ds = Dataset.cargar(datasets_dir / f\"helices_0-{run_seed}.pkl\")\n",
    "\n",
    "tarea = Tarea(\n",
    "    ds,\n",
    "    {x: (clf, {\"var_smoothing\": [x]}) for x in np.logspace(-9, 9, 181)},\n",
    "    # {\"gnb\": (clf, {\"var_smoothing\": np.logspace(-9, 9, 181)})},\n",
    "    seed=main_seed,\n",
    "    scoring=\"accuracy\",\n",
    "    # scoring=\"neg_log_loss\",\n",
    "    split_evaluacion=0.5,\n",
    ")\n",
    "tarea.entrenar()\n",
    "tarea.evaluar()\n",
    "tarea_info = tarea.info\n",
    "n_eval = len(tarea.y_eval)\n",
    "new_metrics = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        x: {\n",
    "            \"eval_logvero\": info.logvero,\n",
    "            \"eval_r2\": info.r2,\n",
    "            \"mean_test_score\": info.busqueda.cv_results_[\"mean_test_score\"][0],\n",
    "            \"std_test_score\": info.busqueda.cv_results_[\"std_test_score\"][0],\n",
    "            \"eval_accuracy\": info.accuracy,\n",
    "        }\n",
    "        for x, info in tarea_info.items()\n",
    "        if x != \"base\"\n",
    "    },\n",
    "    orient=\"index\",\n",
    ")\n",
    "new_metrics[\"rank_test_score\"] = (-new_metrics.mean_test_score).rank().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numbers import Number\n",
    "\n",
    "specs_limits = []\n",
    "for clf, hipers in grillas.items():\n",
    "    for hiper, values in hipers.items():\n",
    "        if len(values) <= 2:\n",
    "            continue\n",
    "        first, last = values[0], values[-1]\n",
    "        if isinstance(first, Number):\n",
    "            specs_limits.append((clf, hiper, first, last))\n",
    "specs_limits = pd.DataFrame(\n",
    "    specs_limits, columns=[\"clf\", \"hiper\", \"min\", \"max\"]\n",
    ").set_index([\"clf\", \"hiper\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = []\n",
    "nolimits = 0\n",
    "for (ds, *_), info in infos.items():\n",
    "    for clf in info.keys():\n",
    "        if clf == \"base\":\n",
    "            continue\n",
    "        clf_limits = specs_limits.xs(clf)\n",
    "        best_params = info[clf].busqueda.best_params_\n",
    "        for hiper, value in best_params.items():\n",
    "            if (hiper in clf_limits.index) and (value in clf_limits.xs(hiper).values):\n",
    "                limits.append((clf, ds, hiper, value))\n",
    "            else:\n",
    "                nolimits += 1\n",
    "limits = pd.DataFrame(limits, columns=[\"ds\", \"clf\", \"hiper\", \"value\"])\n",
    "print(nolimits)\n",
    "limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(1, 4, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-3, 5, 101)[-15:], np.logspace(-3, 6, 118)[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grillas[\"fkdc\"][\"bandwidth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits.value_counts().xs(\"fkdc\").unstack((\"hiper\", \"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "# new_metrics.eval_logvero.plot(label=\"eval\")\n",
    "new_metrics.mean_test_score.plot(label=\"test\")\n",
    "# new_metrics.mean_test_score.mul(n_eval).plot(label=\"test\")\n",
    "ax1.set_ylabel(\"logvero (solid lines)\")\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()\n",
    "new_metrics.eval_accuracy.plot(ax=ax2, linestyle=\"dotted\")\n",
    "ax2.set_ylabel(\"accuracy (dotted lines)\")\n",
    "plt.xscale(\"log\")\n",
    "# plt.xlim(None, 10**-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fkdc.config import n_samples\n",
    "from fkdc.utils import sample\n",
    "\n",
    "pca = PCA(n_components).fit(X)\n",
    "_X = pca.transform(X)\n",
    "datasets_mnist = {\n",
    "    (\"mnist\", seed): Dataset(*sample(_X, y, n_samples=n_samples, random_state=seed))\n",
    "    for seed in run_seeds\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tomados de otros notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sapienza's Swiss Roll\n",
    "> We use the well-known example coined “Swiss roll”, Figure 1(a) and 1(b). We consider a dataset composed of 4 subsets steaming from independent Normal distributions (restricted to the unit square) with mean $\\mu_1 = (.3, .3), \\mu_2 = (.3, .7), \\mu_3 = (.7, .3), \\mu_4 = (.7, .7)$ respectively and constant variance, Figure 1(a). Then, we apply the Swiss Roll transformation, Figure 1(b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox Modesto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distancia de Fermat en Clasificadores de Densidad por Núcleos\n",
    "\n",
    "La mayoría de los algoritmos de clasificación asumen que las observaciones yacen sobre un espacio euclídeo: son escasos los métodos que también son válidos cuando el dominio de las variables aleatorias es una variedad arbitraria. En este ámbito, Loubes & Pelletier [1] proponen un clasificador basado en estimación de densidad por núcleos (\"KDC\") útil en variedades de Riemann conocidas.\n",
    "\n",
    "Más aún, no siempre es conocida la variedad en que yacen los datos: una imagen de 1 megapíxel tiene 1.000.000 de píxeles, pero típicamente representa un objeto (un dígito, una letra, un animal) que - hipotetizamos - podríamos describir con (muchas) menos dimensiones. En estos contextos, se pueden aprender _distancias basadas en densidad_ (DBDs) que permiten estimar la variedad intrínseca de las observaciones a partir de la misma muestra, como la Distancia (muestral) de Fermat,  investigada por Groisman et al. [2]\n",
    "\n",
    "En este trabajo, nos proponemos (1) programar el clasificador KDC, (2) extenderlo para utilizar la distancia muestral de Fermat (\"F-KDC\"), y (3) analizar comparativamente su _performance_ en distintas tareas de clasificación.\n",
    "\n",
    "[1] J.-M. Loubes y B. Pelletier, «A Kernel-Based Classifier on a Riemannian Manifold», Statistics &\n",
    "Decisions, vol. 26, n.º 1, pp. 35-51, mar. 2008, doi: 10.1524/stnd.2008.0911.\n",
    "[2] P. Groisman, M. Jonckheere, y F. Sapienza, «Nonhomogeneous Euclidean First-Passage Percola-\n",
    "tion and Distance Learning», n.º arXiv:1810.09398. arXiv, diciembre de 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(-6, 6, 0.01)\n",
    "\n",
    "\n",
    "def phi(x):\n",
    "    return (2 * pi) ** (-1 / 2) * np.exp(-1 / 2 * x**2)\n",
    "\n",
    "\n",
    "def ind(x, lb=-1 / 2, ub=1 / 2):\n",
    "    return np.where((x >= lb) & (x < ub), 1 / (ub - lb), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(xs, phi(xs))\n",
    "plt.plot(xs, ind(xs, -1.2, 1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.sort(sp.stats.norm().rvs(200)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for bw in [0.03, 0.1, 0.3, 1]:\n",
    "    kde = KernelDensity(kernel=\"gaussian\", bandwidth=bw).fit(xs)\n",
    "    grid = np.arange(-5, 5, 0.01).reshape(-1, 1)\n",
    "    dens = np.exp(kde.score_samples(grid))\n",
    "    plt.plot(grid, dens, label=f\"h = {bw}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.norm().pdf(grid).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "grid = np.arange(-5, 5, 0.01).reshape(-1, 1)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "for kernel, ax in zip([\"gaussian\", \"tophat\"], axs, strict=False):\n",
    "    ax.plot(\n",
    "        grid, sp.stats.norm().pdf(grid), alpha=0.5, color=\"gray\", linestyle=\"dashed\"\n",
    "    )\n",
    "    for bw in [0.1, 0.3, 1, 3]:\n",
    "        kde = KernelDensity(kernel=kernel, bandwidth=bw).fit(xs)\n",
    "        dens = np.exp(kde.score_samples(grid))\n",
    "        ax.plot(grid, dens, label=f\"h = {bw}\", alpha=0.5)\n",
    "        ax.set_title(f\"Kernel = {kernel}\")\n",
    "        ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "hs = np.array([0.1, 0.5, 0.9, 0.98])\n",
    "ds = np.array([1, 2, 5, 10, 20, 25])\n",
    "df = pd.DataFrame([(h, d, h**d) for h in hs for d in ds], columns=[\"h\", \"d\", \"h**d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot(index=\"h\", columns=\"d\", values=\"h**d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "lb, ub = -1, 1\n",
    "span = ub - lb\n",
    "N = 100_000\n",
    "d = 3\n",
    "X = stats.uniform(lb, span).rvs((N, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fhat_0(X, h):\n",
    "    N, d = X.shape\n",
    "    return sum(np.apply_along_axis(all, 1, (np.abs(X) < h))) / (N * (2 * h) ** d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_fhat_0_1k = pd.Series({h: fhat_0(X, h) for h in np.linspace(0.01, 1, 201)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected_fhat_0.plot()\n",
    "# expected_fhat_0_10k.plot()\n",
    "expected_fhat_0_1k.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhat_0(X, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "h = 0.88\n",
    "\n",
    "sk_fhat = KernelDensity(kernel=\"tophat\", bandwidth=h).fit(X)\n",
    "np.exp(sk_fhat.score([np.zeros_like(X[0, :])])), fhat_0(X, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# hs = np.array([0.1, 0.5, 0.9, 0.98])\n",
    "hs = [0.25, 0.5, 0.9, 0.95]\n",
    "ds = np.array([1, 2, 5, 10, 20, 25])\n",
    "ds = np.arange(1, 51, 1)\n",
    "df = pd.DataFrame([(h, d, h**d) for h in hs for d in ds], columns=[\"h\", \"d\", \"h**d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = df.set_index([\"d\", \"h\"]).unstack()[\"h**d\"]\n",
    "data.plot(figsize=(12, 4))\n",
    "plt.title(\"Proporción de las X dentro de un $d$-cubo de lado $h$\")\n",
    "# plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.95**50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p-wspm's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "p = np.arange(1, 100)\n",
    "y = np.power(2, (p + 1) / p)\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "- gbt con mayot max_depth; empata top perfs?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fkdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
